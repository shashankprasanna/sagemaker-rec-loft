{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Recommender System with Amazon SageMaker Factorization Machines and BlazingText\n",
    "\n",
    "---\n",
    "\n",
    "## Background\n",
    "\n",
    "- Recommender systems were a catalyst for ML's popularity (Amazon, Netflix Prize)\n",
    "- User item matrix factorization is a core methodology\n",
    "- Factorization machines combine linear prediction with a factorized representation of pairwise feature interaction\n",
    "\n",
    "$$\\hat{r} = w_0 + \\sum_{i} {w_i x_i} + \\sum_{i} {\\sum_{j > i} {\\langle v_i, v_j \\rangle x_i x_j}}$$\n",
    "\n",
    "- SageMaker has a highly scalable factorization machines algorithm built-in\n",
    "- To learn more about the math behind _factorization machines_, [this paper](https://www.csie.ntu.edu.tw/~b97053/paper/Rendle2010FM.pdf) is a great resource\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Setup\n",
    "\n",
    "### Follow instructions on-screen\n",
    "\n",
    "1. Spin up SageMaker hosted notebook instance in console\n",
    "2. Add SageMaker IAM policy to this SageMaker notebook to allow S3 read/write access\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Data preparation\n",
    "\n",
    "1. Create new S3 bucket (first cell)\n",
    "2. Import necessary libraries (second cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "base = 'DEMO-ny-loft-recommender'\n",
    "prefix = 'sagemaker/' + base\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import boto3\n",
    "import json\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import sagemaker.amazon.common as smac\n",
    "from sagemaker.predictor import json_deserializer\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import dataset\n",
    "[Amazon Reviews AWS Public Dataset](https://s3.amazonaws.com/amazon-reviews-pds/readme.html)\n",
    "- 1 to 5 star ratings\n",
    "- 2M+ Amazon customers\n",
    "- 160K+ digital videos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://amazon-reviews-pds/tsv/amazon_reviews_us_Digital_Video_Download_v1_00.tsv.gz to ../../../../tmp/recsys/amazon_reviews_us_Digital_Video_Download_v1_00.tsv.gz\n"
     ]
    }
   ],
   "source": [
    "!mkdir /tmp/recsys/\n",
    "!aws s3 cp s3://amazon-reviews-pds/tsv/amazon_reviews_us_Digital_Video_Download_v1_00.tsv.gz /tmp/recsys/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 92523: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 343254: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 524626: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 623024: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 977412: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1496867: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1711638: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1787213: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 2395306: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 2527690: expected 15 fields, saw 22\\n'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marketplace</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_category</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>vine</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>12190288</td>\n",
       "      <td>R3FU16928EP5TC</td>\n",
       "      <td>B00AYB1482</td>\n",
       "      <td>668895143</td>\n",
       "      <td>Enlightened: Season 1</td>\n",
       "      <td>Digital_Video_Download</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>I loved it and I wish there was a season 3</td>\n",
       "      <td>I loved it and I wish there was a season 3... ...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>30549954</td>\n",
       "      <td>R1IZHHS1MH3AQ4</td>\n",
       "      <td>B00KQD28OM</td>\n",
       "      <td>246219280</td>\n",
       "      <td>Vicious</td>\n",
       "      <td>Digital_Video_Download</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>As always it seems that the best shows come fr...</td>\n",
       "      <td>As always it seems that the best shows come fr...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>52895410</td>\n",
       "      <td>R52R85WC6TIAH</td>\n",
       "      <td>B01489L5LQ</td>\n",
       "      <td>534732318</td>\n",
       "      <td>After Words</td>\n",
       "      <td>Digital_Video_Download</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Charming movie</td>\n",
       "      <td>This movie isn't perfect, but it gets a lot of...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>27072354</td>\n",
       "      <td>R7HOOYTVIB0DS</td>\n",
       "      <td>B008LOVIIK</td>\n",
       "      <td>239012694</td>\n",
       "      <td>Masterpiece: Inspector Lewis Season 5</td>\n",
       "      <td>Digital_Video_Download</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>excellant this is what tv should be</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>26939022</td>\n",
       "      <td>R1XQ2N5CDOZGNX</td>\n",
       "      <td>B0094LZMT0</td>\n",
       "      <td>535858974</td>\n",
       "      <td>On The Waterfront</td>\n",
       "      <td>Digital_Video_Download</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Brilliant film from beginning to end</td>\n",
       "      <td>Brilliant film from beginning to end. All of t...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  marketplace  customer_id       review_id  product_id  product_parent  \\\n",
       "0          US     12190288  R3FU16928EP5TC  B00AYB1482       668895143   \n",
       "1          US     30549954  R1IZHHS1MH3AQ4  B00KQD28OM       246219280   \n",
       "2          US     52895410   R52R85WC6TIAH  B01489L5LQ       534732318   \n",
       "3          US     27072354   R7HOOYTVIB0DS  B008LOVIIK       239012694   \n",
       "4          US     26939022  R1XQ2N5CDOZGNX  B0094LZMT0       535858974   \n",
       "\n",
       "                           product_title        product_category  star_rating  \\\n",
       "0                  Enlightened: Season 1  Digital_Video_Download            5   \n",
       "1                                Vicious  Digital_Video_Download            5   \n",
       "2                            After Words  Digital_Video_Download            4   \n",
       "3  Masterpiece: Inspector Lewis Season 5  Digital_Video_Download            5   \n",
       "4                      On The Waterfront  Digital_Video_Download            5   \n",
       "\n",
       "   helpful_votes  total_votes vine verified_purchase  \\\n",
       "0              0            0    N                 Y   \n",
       "1              0            0    N                 Y   \n",
       "2             17           18    N                 Y   \n",
       "3              0            0    N                 Y   \n",
       "4              0            0    N                 Y   \n",
       "\n",
       "                                     review_headline  \\\n",
       "0         I loved it and I wish there was a season 3   \n",
       "1  As always it seems that the best shows come fr...   \n",
       "2                                     Charming movie   \n",
       "3                                         Five Stars   \n",
       "4               Brilliant film from beginning to end   \n",
       "\n",
       "                                         review_body review_date  \n",
       "0  I loved it and I wish there was a season 3... ...  2015-08-31  \n",
       "1  As always it seems that the best shows come fr...  2015-08-31  \n",
       "2  This movie isn't perfect, but it gets a lot of...  2015-08-31  \n",
       "3                excellant this is what tv should be  2015-08-31  \n",
       "4  Brilliant film from beginning to end. All of t...  2015-08-31  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/tmp/recsys/amazon_reviews_us_Digital_Video_Download_v1_00.tsv.gz', delimiter='\\t',error_bad_lines=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset columns:\n",
    "\n",
    "- `marketplace`: 2-letter country code (in this case all \"US\").\n",
    "- `customer_id`: Random identifier that can be used to aggregate reviews written by a single author.\n",
    "- `review_id`: A unique ID for the review.\n",
    "- `product_id`: The Amazon Standard Identification Number (ASIN).  `http://www.amazon.com/dp/<ASIN>` links to the product's detail page.\n",
    "- `product_parent`: The parent of that ASIN.  Multiple ASINs (color or format variations of the same product) can roll up into a single parent parent.\n",
    "- `product_title`: Title description of the product.\n",
    "- `product_category`: Broad product category that can be used to group reviews (in this case digital videos).\n",
    "- `star_rating`: The review's rating (1 to 5 stars).\n",
    "- `helpful_votes`: Number of helpful votes for the review.\n",
    "- `total_votes`: Number of total votes the review received.\n",
    "- `vine`: Was the review written as part of the [Vine](https://www.amazon.com/gp/vine/help) program?\n",
    "- `verified_purchase`: Was the review from a verified purchase?\n",
    "- `review_headline`: The title of the review itself.\n",
    "- `review_body`: The text of the review.\n",
    "- `review_date`: The date the review was written.\n",
    "\n",
    "Drop some fields that won't be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['customer_id', 'product_id', 'product_title', 'star_rating', 'review_date']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop some fields that won't be used for now. We'll reintroduce these later in a format that is expected by the algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customers\n",
      " 0.00       1.0\n",
      "0.01       1.0\n",
      "0.02       1.0\n",
      "0.03       1.0\n",
      "0.04       1.0\n",
      "0.05       1.0\n",
      "0.10       1.0\n",
      "0.25       1.0\n",
      "0.50       1.0\n",
      "0.75       2.0\n",
      "0.90       4.0\n",
      "0.95       5.0\n",
      "0.96       6.0\n",
      "0.97       7.0\n",
      "0.98       9.0\n",
      "0.99      13.0\n",
      "1.00    2704.0\n",
      "Name: customer_id, dtype: float64\n",
      "products\n",
      " 0.00        1.00\n",
      "0.01        1.00\n",
      "0.02        1.00\n",
      "0.03        1.00\n",
      "0.04        1.00\n",
      "0.05        1.00\n",
      "0.10        1.00\n",
      "0.25        1.00\n",
      "0.50        3.00\n",
      "0.75        9.00\n",
      "0.90       31.00\n",
      "0.95       73.00\n",
      "0.96       95.00\n",
      "0.97      130.00\n",
      "0.98      199.00\n",
      "0.99      386.67\n",
      "1.00    32790.00\n",
      "Name: product_id, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "customers = df['customer_id'].value_counts()\n",
    "products = df['product_id'].value_counts()\n",
    "\n",
    "quantiles = [0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95, 0.96, 0.97, 0.98, 0.99, 1]\n",
    "print('customers\\n', customers.quantile(quantiles))\n",
    "print('products\\n', products.quantile(quantiles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter out customers who haven't rated many movies.\n",
    "\n",
    "Only keep customers who've rated more than or equal to 5 products\n",
    "And products which have more than or equal to 10 ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers = customers[customers >= 5]\n",
    "products = products[products >= 10]\n",
    "\n",
    "reduced_df = df.merge(pd.DataFrame({'customer_id': customers.index})).merge(pd.DataFrame({'product_id': products.index}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a sequential index for customers and movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers = reduced_df['customer_id'].value_counts()\n",
    "products = reduced_df['product_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_title</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_date</th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27072354</td>\n",
       "      <td>B008LOVIIK</td>\n",
       "      <td>Masterpiece: Inspector Lewis Season 5</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>10463</td>\n",
       "      <td>140450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16030865</td>\n",
       "      <td>B008LOVIIK</td>\n",
       "      <td>Masterpiece: Inspector Lewis Season 5</td>\n",
       "      <td>5</td>\n",
       "      <td>2014-06-20</td>\n",
       "      <td>489</td>\n",
       "      <td>140450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44025160</td>\n",
       "      <td>B008LOVIIK</td>\n",
       "      <td>Masterpiece: Inspector Lewis Season 5</td>\n",
       "      <td>5</td>\n",
       "      <td>2014-05-27</td>\n",
       "      <td>32100</td>\n",
       "      <td>140450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18602179</td>\n",
       "      <td>B008LOVIIK</td>\n",
       "      <td>Masterpiece: Inspector Lewis Season 5</td>\n",
       "      <td>5</td>\n",
       "      <td>2014-12-23</td>\n",
       "      <td>2237</td>\n",
       "      <td>140450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14424972</td>\n",
       "      <td>B008LOVIIK</td>\n",
       "      <td>Masterpiece: Inspector Lewis Season 5</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>32340</td>\n",
       "      <td>140450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  product_id                          product_title  \\\n",
       "0     27072354  B008LOVIIK  Masterpiece: Inspector Lewis Season 5   \n",
       "1     16030865  B008LOVIIK  Masterpiece: Inspector Lewis Season 5   \n",
       "2     44025160  B008LOVIIK  Masterpiece: Inspector Lewis Season 5   \n",
       "3     18602179  B008LOVIIK  Masterpiece: Inspector Lewis Season 5   \n",
       "4     14424972  B008LOVIIK  Masterpiece: Inspector Lewis Season 5   \n",
       "\n",
       "   star_rating review_date   user    item  \n",
       "0            5  2015-08-31  10463  140450  \n",
       "1            5  2014-06-20    489  140450  \n",
       "2            5  2014-05-27  32100  140450  \n",
       "3            5  2014-12-23   2237  140450  \n",
       "4            5  2015-08-31  32340  140450  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_index = pd.DataFrame({'customer_id': customers.index, 'user': np.arange(customers.shape[0])})\n",
    "product_index = pd.DataFrame({'product_id': products.index, \n",
    "                              'item': np.arange(products.shape[0]) + customer_index.shape[0]})\n",
    "\n",
    "reduced_df = reduced_df.merge(customer_index).merge(product_index)\n",
    "reduced_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count days since first review (included as a feature to capture trend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_df['review_date'] = pd.to_datetime(reduced_df['review_date'])\n",
    "customer_first_date = reduced_df.groupby('customer_id')['review_date'].min().reset_index()\n",
    "customer_first_date.columns = ['customer_id', 'first_review_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_df = reduced_df.merge(customer_first_date)\n",
    "reduced_df['days_since_first'] = (reduced_df['review_date'] - reduced_df['first_review_date']).dt.days\n",
    "reduced_df['days_since_first'] = reduced_df['days_since_first'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_title</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_date</th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>first_review_date</th>\n",
       "      <th>days_since_first</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27072354</td>\n",
       "      <td>B008LOVIIK</td>\n",
       "      <td>Masterpiece: Inspector Lewis Season 5</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>10463</td>\n",
       "      <td>140450</td>\n",
       "      <td>2015-04-21</td>\n",
       "      <td>132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27072354</td>\n",
       "      <td>B003V8GGA6</td>\n",
       "      <td>Wallace &amp; Gromit's Cracking Contraptions</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>10463</td>\n",
       "      <td>144955</td>\n",
       "      <td>2015-04-21</td>\n",
       "      <td>132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27072354</td>\n",
       "      <td>B00SY9HO8U</td>\n",
       "      <td>Suburban Gothic</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-07-22</td>\n",
       "      <td>10463</td>\n",
       "      <td>142601</td>\n",
       "      <td>2015-04-21</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27072354</td>\n",
       "      <td>B008Y7EYSK</td>\n",
       "      <td>The Woman in Black</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-07-22</td>\n",
       "      <td>10463</td>\n",
       "      <td>140712</td>\n",
       "      <td>2015-04-21</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27072354</td>\n",
       "      <td>B0079W7X98</td>\n",
       "      <td>Masterpiece: Inspector Lewis Season 2</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-06-16</td>\n",
       "      <td>10463</td>\n",
       "      <td>140410</td>\n",
       "      <td>2015-04-21</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  product_id                             product_title  \\\n",
       "0     27072354  B008LOVIIK     Masterpiece: Inspector Lewis Season 5   \n",
       "1     27072354  B003V8GGA6  Wallace & Gromit's Cracking Contraptions   \n",
       "2     27072354  B00SY9HO8U                           Suburban Gothic   \n",
       "3     27072354  B008Y7EYSK                        The Woman in Black   \n",
       "4     27072354  B0079W7X98     Masterpiece: Inspector Lewis Season 2   \n",
       "\n",
       "   star_rating review_date   user    item first_review_date  days_since_first  \n",
       "0            5  2015-08-31  10463  140450        2015-04-21             132.0  \n",
       "1            5  2015-08-31  10463  144955        2015-04-21             132.0  \n",
       "2            1  2015-07-22  10463  142601        2015-04-21              92.0  \n",
       "3            4  2015-07-22  10463  140712        2015-04-21              92.0  \n",
       "4            5  2015-06-16  10463  140410        2015-04-21              56.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = reduced_df.groupby('customer_id').last().reset_index()\n",
    "\n",
    "train_df = reduced_df.merge(test_df[['customer_id', 'product_id']], \n",
    "                            on=['customer_id', 'product_id'], \n",
    "                            how='outer', \n",
    "                            indicator=True)\n",
    "train_df = train_df[(train_df['_merge'] == 'left_only')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Factorization machines expects data to look something like:\n",
    "  - Sparse matrix\n",
    "  - Target variable is that user's rating for a movie\n",
    "  - One-hot encoding for users ($N$ features)\n",
    "  - One-hot encoding for movies ($M$ features)\n",
    "\n",
    "|Rating|User1|User2|...|UserN|Movie1|Movie2|Movie3|...|MovieM|Feature1|Feature2|...|\n",
    "|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
    "|4|1|0|...|0|1|0|0|...|0|20|2.2|...|\n",
    "|5|1|0|...|0|0|1|0|...|0|17|9.1|...|\n",
    "|3|0|1|...|0|1|0|0|...|0|3|11.0|...|\n",
    "|4|0|1|...|0|0|0|1|...|0|15|6.4|...|\n",
    "\n",
    "\n",
    "- Wouldn't want to hold this full matrix in memory\n",
    "  - Create a sparse matrix\n",
    "  - Designed to work efficiently with CPUs. Some parts of training for more dense matrices can be parallelized with GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_csr_matrix(df, num_users, num_items):\n",
    "    feature_dim = num_users + num_items + 1\n",
    "    data = np.concatenate([np.array([1] * df.shape[0]),\n",
    "                           np.array([1] * df.shape[0]),\n",
    "                           df['days_since_first'].values])\n",
    "    row = np.concatenate([np.arange(df.shape[0])] * 3)\n",
    "    col = np.concatenate([df['user'].values,\n",
    "                          df['item'].values,\n",
    "                          np.array([feature_dim - 1] * df.shape[0])])\n",
    "    return csr_matrix((data, (row, col)), \n",
    "                      shape=(df.shape[0], feature_dim), \n",
    "                      dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csr = to_csr_matrix(train_df, customer_index.shape[0], product_index.shape[0])\n",
    "test_csr = to_csr_matrix(test_df, customer_index.shape[0], product_index.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to sparse recordIO-wrapped protobuf that SageMaker factorization machines expects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_s3_protobuf(csr, label, bucket, prefix, channel='train', splits=10):\n",
    "    indices = np.array_split(np.arange(csr.shape[0]), splits)\n",
    "    for i in range(len(indices)):\n",
    "        index = indices[i]\n",
    "        buf = io.BytesIO()\n",
    "        smac.write_spmatrix_to_sparse_tensor(buf, csr[index, ], label[index])\n",
    "        buf.seek(0)\n",
    "        boto3.client('s3').upload_fileobj(buf, bucket, '{}/{}/data-{}'.format(prefix, channel, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_s3_protobuf(train_csr, train_df['star_rating'].values.astype(np.float32), bucket, prefix)\n",
    "to_s3_protobuf(test_csr, test_df['star_rating'].values.astype(np.float32), bucket, prefix, channel='test', splits=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3 - Train Factorization Machines (FM) using SageMaker\n",
    "\n",
    "- Create a [SageMaker Python SDK](https://github.com/aws/sagemaker-python-sdk) estimator to run a training jobs and specify:\n",
    "  - Algorithm container image\n",
    "  - IAM role\n",
    "  - Hardware setup\n",
    "  - S3 output location\n",
    "  - Algorithm hyperparameters\n",
    "    - `feature_dim`: $N + M + 1$ (additional feature is `days_since_first` to capture trend)\n",
    "    - `num_factors`: number of factor dimensions (increasing too much can lead to overfitting)\n",
    "    - `epochs`: number of full passes through the dataset\n",
    "- `.fit()` points to training and test data in S3 and begins the training job\n",
    "\n",
    "**Note**: For AWS accounts registered in conjunction with a workshop, default instance limits may prevent the use of `ml.c5.2xlarge` (and other equally powerful instances), and may require a lower value for `train_instance_count` depending on the instance type chosen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-20 03:05:18 Starting - Starting the training job...\n",
      "2019-08-20 03:05:21 Starting - Launching requested ML instances......\n",
      "2019-08-20 03:06:25 Starting - Preparing the instances for training......\n",
      "2019-08-20 03:07:46 Downloading - Downloading input data\n",
      "2019-08-20 03:07:46 Training - Downloading the training image..\n",
      "\u001b[32mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[32m/opt/amazon/lib/python2.7/site-packages/pandas/util/nosetester.py:13: DeprecationWarning: Importing from numpy.testing.nosetester is deprecated, import from numpy.testing instead.\n",
      "  from numpy.testing import nosetester\u001b[0m\n",
      "\u001b[32m[08/20/2019 03:08:01 INFO 139979787347776] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-conf.json: {u'factors_lr': u'0.0001', u'linear_init_sigma': u'0.01', u'epochs': 1, u'_wd': u'1.0', u'_num_kv_servers': u'auto', u'use_bias': u'true', u'factors_init_sigma': u'0.001', u'_log_level': u'info', u'bias_init_method': u'normal', u'linear_init_method': u'normal', u'linear_lr': u'0.001', u'factors_init_method': u'normal', u'_tuning_objective_metric': u'', u'bias_wd': u'0.01', u'use_linear': u'true', u'bias_lr': u'0.1', u'mini_batch_size': u'1000', u'_use_full_symbolic': u'true', u'batch_metrics_publish_interval': u'500', u'bias_init_sigma': u'0.01', u'_num_gpus': u'auto', u'_data_format': u'record', u'factors_wd': u'0.00001', u'linear_wd': u'0.001', u'_kvstore': u'auto', u'_learning_rate': u'1.0', u'_optimizer': u'adam'}\u001b[0m\n",
      "\u001b[32m[08/20/2019 03:08:01 INFO 139979787347776] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'epochs': u'3', u'feature_dim': u'178730', u'mini_batch_size': u'1000', u'predictor_type': u'regressor', u'num_factors': u'256'}\u001b[0m\n",
      "\u001b[32m[08/20/2019 03:08:01 INFO 139979787347776] Final configuration: {u'factors_lr': u'0.0001', u'linear_init_sigma': u'0.01', u'epochs': u'3', u'feature_dim': u'178730', u'num_factors': u'256', u'_wd': u'1.0', u'_num_kv_servers': u'auto', u'use_bias': u'true', u'factors_init_sigma': u'0.001', u'_log_level': u'info', u'bias_init_method': u'normal', u'linear_init_method': u'normal', u'linear_lr': u'0.001', u'factors_init_method': u'normal', u'_tuning_objective_metric': u'', u'bias_wd': u'0.01', u'use_linear': u'true', u'bias_lr': u'0.1', u'mini_batch_size': u'1000', u'_use_full_symbolic': u'true', u'batch_metrics_publish_interval': u'500', u'predictor_type': u'regressor', u'bias_init_sigma': u'0.01', u'_num_gpus': u'auto', u'_data_format': u'record', u'factors_wd': u'0.00001', u'linear_wd': u'0.001', u'_kvstore': u'auto', u'_learning_rate': u'1.0', u'_optimizer': u'adam'}\u001b[0m\n",
      "\u001b[32m[08/20/2019 03:08:01 WARNING 139979787347776] Loggers have already been setup.\u001b[0m\n",
      "\u001b[33mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[32m[08/20/2019 03:08:02 INFO 139979787347776] Launching parameter server for role server\u001b[0m\n",
      "\u001b[32m[08/20/2019 03:08:02 INFO 139979787347776] {'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/e788c703-3772-473e-b2c5-8757e141dc90', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'AWS_REGION': 'us-west-2', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'DEMO-ny-loft-recommender-2019-08-20-03-05-18-645', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '4', 'HOSTNAME': 'ip-10-0-162-95.us-west-2.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/c6975bec-ec83-4465-8e96-9fb4794f3919', 'PWD': '/', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-west-2:453691756499:training-job/demo-ny-loft-recommender-2019-08-20-03-05-18-645', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[32m[08/20/2019 03:08:02 INFO 139979787347776] envs={'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/e788c703-3772-473e-b2c5-8757e141dc90', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'DMLC_NUM_WORKER': '4', 'DMLC_PS_ROOT_PORT': '9000', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'DMLC_PS_ROOT_URI': '10.0.157.195', 'AWS_REGION': 'us-west-2', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'DEMO-ny-loft-recommender-2019-08-20-03-05-18-645', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '4', 'HOSTNAME': 'ip-10-0-162-95.us-west-2.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/c6975bec-ec83-4465-8e96-9fb4794f3919', 'DMLC_ROLE': 'server', 'PWD': '/', 'DMLC_NUM_SERVER': '4', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-west-2:453691756499:training-job/demo-ny-loft-recommender-2019-08-20-03-05-18-645', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[32m[08/20/2019 03:08:02 INFO 139979787347776] Environment: {'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/e788c703-3772-473e-b2c5-8757e141dc90', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'DMLC_PS_ROOT_PORT': '9000', 'DMLC_NUM_WORKER': '4', 'SAGEMAKER_HTTP_PORT': '8080', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'DMLC_PS_ROOT_URI': '10.0.157.195', 'AWS_REGION': 'us-west-2', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'DEMO-ny-loft-recommender-2019-08-20-03-05-18-645', 'HOME': '/root', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '4', 'HOSTNAME': 'ip-10-0-162-95.us-west-2.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/c6975bec-ec83-4465-8e96-9fb4794f3919', 'DMLC_ROLE': 'worker', 'PWD': '/', 'DMLC_NUM_SERVER': '4', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-west-2:453691756499:training-job/demo-ny-loft-recommender-2019-08-20-03-05-18-645', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[32mProcess 39 is a shell:server.\u001b[0m\n",
      "\u001b[32mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[32m[08/20/2019 03:08:02 INFO 139979787347776] Using default worker.\u001b[0m\n",
      "\u001b[32m[2019-08-20 03:08:02.678] [tensorio] [warning] TensorIO is already initialized; ignoring the initialization routine.\u001b[0m\n",
      "\u001b[32m[2019-08-20 03:08:02.684] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 9, \"num_examples\": 1, \"num_bytes\": 71356}\u001b[0m\n",
      "\u001b[33m/opt/amazon/lib/python2.7/site-packages/pandas/util/nosetester.py:13: DeprecationWarning: Importing from numpy.testing.nosetester is deprecated, import from numpy.testing instead.\n",
      "  from numpy.testing import nosetester\u001b[0m\n",
      "\u001b[33m[08/20/2019 03:08:02 INFO 140385400035136] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-conf.json: {u'factors_lr': u'0.0001', u'linear_init_sigma': u'0.01', u'epochs': 1, u'_wd': u'1.0', u'_num_kv_servers': u'auto', u'use_bias': u'true', u'factors_init_sigma': u'0.001', u'_log_level': u'info', u'bias_init_method': u'normal', u'linear_init_method': u'normal', u'linear_lr': u'0.001', u'factors_init_method': u'normal', u'_tuning_objective_metric': u'', u'bias_wd': u'0.01', u'use_linear': u'true', u'bias_lr': u'0.1', u'mini_batch_size': u'1000', u'_use_full_symbolic': u'true', u'batch_metrics_publish_interval': u'500', u'bias_init_sigma': u'0.01', u'_num_gpus': u'auto', u'_data_format': u'record', u'factors_wd': u'0.00001', u'linear_wd': u'0.001', u'_kvstore': u'auto', u'_learning_rate': u'1.0', u'_optimizer': u'adam'}\u001b[0m\n",
      "\u001b[33m[08/20/2019 03:08:02 INFO 140385400035136] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'epochs': u'3', u'feature_dim': u'178730', u'mini_batch_size': u'1000', u'predictor_type': u'regressor', u'num_factors': u'256'}\u001b[0m\n",
      "\u001b[33m[08/20/2019 03:08:02 INFO 140385400035136] Final configuration: {u'factors_lr': u'0.0001', u'linear_init_sigma': u'0.01', u'epochs': u'3', u'feature_dim': u'178730', u'num_factors': u'256', u'_wd': u'1.0', u'_num_kv_servers': u'auto', u'use_bias': u'true', u'factors_init_sigma': u'0.001', u'_log_level': u'info', u'bias_init_method': u'normal', u'linear_init_method': u'normal', u'linear_lr': u'0.001', u'factors_init_method': u'normal', u'_tuning_objective_metric': u'', u'bias_wd': u'0.01', u'use_linear': u'true', u'bias_lr': u'0.1', u'mini_batch_size': u'1000', u'_use_full_symbolic': u'true', u'batch_metrics_publish_interval': u'500', u'predictor_type': u'regressor', u'bias_init_sigma': u'0.01', u'_num_gpus': u'auto', u'_data_format': u'record', u'factors_wd': u'0.00001', u'linear_wd': u'0.001', u'_kvstore': u'auto', u'_learning_rate': u'1.0', u'_optimizer': u'adam'}\u001b[0m\n",
      "\u001b[33m[08/20/2019 03:08:02 WARNING 140385400035136] Loggers have already been setup.\u001b[0m\n",
      "\u001b[33m[08/20/2019 03:08:02 INFO 140385400035136] Launching parameter server for role server\u001b[0m\n",
      "\u001b[33m[08/20/2019 03:08:02 INFO 140385400035136] {'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/0371847d-2b01-42e2-a1a2-f787200dcb7e', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'AWS_REGION': 'us-west-2', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'DEMO-ny-loft-recommender-2019-08-20-03-05-18-645', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '4', 'HOSTNAME': 'ip-10-0-156-189.us-west-2.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/c6e6c5de-ef9d-4a03-bd6d-b951c0f21d1c', 'PWD': '/', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-west-2:453691756499:training-job/demo-ny-loft-recommender-2019-08-20-03-05-18-645', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[33m[08/20/2019 03:08:02 INFO 140385400035136] envs={'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/0371847d-2b01-42e2-a1a2-f787200dcb7e', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'DMLC_NUM_WORKER': '4', 'DMLC_PS_ROOT_PORT': '9000', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'DMLC_PS_ROOT_URI': '10.0.157.195', 'AWS_REGION': 'us-west-2', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'DEMO-ny-loft-recommender-2019-08-20-03-05-18-645', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '4', 'HOSTNAME': 'ip-10-0-156-189.us-west-2.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/c6e6c5de-ef9d-4a03-bd6d-b951c0f21d1c', 'DMLC_ROLE': 'server', 'PWD': '/', 'DMLC_NUM_SERVER': '4', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-west-2:453691756499:training-job/demo-ny-loft-recommender-2019-08-20-03-05-18-645', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[33m[08/20/2019 03:08:02 INFO 140385400035136] Environment: {'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/0371847d-2b01-42e2-a1a2-f787200dcb7e', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'DMLC_PS_ROOT_PORT': '9000', 'DMLC_NUM_WORKER': '4', 'SAGEMAKER_HTTP_PORT': '8080', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'DMLC_PS_ROOT_URI': '10.0.157.195', 'AWS_REGION': 'us-west-2', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'DEMO-ny-loft-recommender-2019-08-20-03-05-18-645', 'HOME': '/root', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '4', 'HOSTNAME': 'ip-10-0-156-189.us-west-2.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/c6e6c5de-ef9d-4a03-bd6d-b951c0f21d1c', 'DMLC_ROLE': 'worker', 'PWD': '/', 'DMLC_NUM_SERVER': '4', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-west-2:453691756499:training-job/demo-ny-loft-recommender-2019-08-20-03-05-18-645', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[33mProcess 39 is a shell:server.\u001b[0m\n",
      "\u001b[33mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[33m[08/20/2019 03:08:02 INFO 140385400035136] Using default worker.\u001b[0m\n",
      "\u001b[33m[2019-08-20 03:08:02.379] [tensorio] [warning] TensorIO is already initialized; ignoring the initialization routine.\u001b[0m\n",
      "\u001b[33m[2019-08-20 03:08:02.384] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 9, \"num_examples\": 1, \"num_bytes\": 71212}\u001b[0m\n",
      "\u001b[33m[08/20/2019 03:08:02 INFO 140385400035136] nvidia-smi took: 0.0251200199127 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[33m[08/20/2019 03:08:02 INFO 140385400035136] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[33m[08/20/2019 03:08:02 INFO 140385400035136] [Sparse network] Building a sparse network.\u001b[0m\n",
      "\u001b[33m[08/20/2019 03:08:02 INFO 140385400035136] Create Store: dist_async\u001b[0m\n",
      "\u001b[31mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[31m/opt/amazon/lib/python2.7/site-packages/pandas/util/nosetester.py:13: DeprecationWarning: Importing from numpy.testing.nosetester is deprecated, import from numpy.testing instead.\n",
      "  from numpy.testing import nosetester\u001b[0m\n",
      "\u001b[31m[08/20/2019 03:08:01 INFO 140399032596288] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-conf.json: {u'factors_lr': u'0.0001', u'linear_init_sigma': u'0.01', u'epochs': 1, u'_wd': u'1.0', u'_num_kv_servers': u'auto', u'use_bias': u'true', u'factors_init_sigma': u'0.001', u'_log_level': u'info', u'bias_init_method': u'normal', u'linear_init_method': u'normal', u'linear_lr': u'0.001', u'factors_init_method': u'normal', u'_tuning_objective_metric': u'', u'bias_wd': u'0.01', u'use_linear': u'true', u'bias_lr': u'0.1', u'mini_batch_size': u'1000', u'_use_full_symbolic': u'true', u'batch_metrics_publish_interval': u'500', u'bias_init_sigma': u'0.01', u'_num_gpus': u'auto', u'_data_format': u'record', u'factors_wd': u'0.00001', u'linear_wd': u'0.001', u'_kvstore': u'auto', u'_learning_rate': u'1.0', u'_optimizer': u'adam'}\u001b[0m\n",
      "\u001b[31m[08/20/2019 03:08:01 INFO 140399032596288] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'epochs': u'3', u'feature_dim': u'178730', u'mini_batch_size': u'1000', u'predictor_type': u'regressor', u'num_factors': u'256'}\u001b[0m\n",
      "\u001b[31m[08/20/2019 03:08:01 INFO 140399032596288] Final configuration: {u'factors_lr': u'0.0001', u'linear_init_sigma': u'0.01', u'epochs': u'3', u'feature_dim': u'178730', u'num_factors': u'256', u'_wd': u'1.0', u'_num_kv_servers': u'auto', u'use_bias': u'true', u'factors_init_sigma': u'0.001', u'_log_level': u'info', u'bias_init_method': u'normal', u'linear_init_method': u'normal', u'linear_lr': u'0.001', u'factors_init_method': u'normal', u'_tuning_objective_metric': u'', u'bias_wd': u'0.01', u'use_linear': u'true', u'bias_lr': u'0.1', u'mini_batch_size': u'1000', u'_use_full_symbolic': u'true', u'batch_metrics_publish_interval': u'500', u'predictor_type': u'regressor', u'bias_init_sigma': u'0.01', u'_num_gpus': u'auto', u'_data_format': u'record', u'factors_wd': u'0.00001', u'linear_wd': u'0.001', u'_kvstore': u'auto', u'_learning_rate': u'1.0', u'_optimizer': u'adam'}\u001b[0m\n",
      "\u001b[31m[08/20/2019 03:08:01 WARNING 140399032596288] Loggers have already been setup.\u001b[0m\n",
      "\u001b[31m[08/20/2019 03:08:02 INFO 140399032596288] Launching parameter server for role scheduler\u001b[0m\n",
      "\u001b[31m[08/20/2019 03:08:02 INFO 140399032596288] {'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/8bf00102-0f0e-4952-857a-ed2435e941c6', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'AWS_REGION': 'us-west-2', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'DEMO-ny-loft-recommender-2019-08-20-03-05-18-645', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '4', 'HOSTNAME': 'ip-10-0-157-195.us-west-2.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/39c636a8-c8d9-4e60-bb91-dd2a206306af', 'PWD': '/', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-west-2:453691756499:training-job/demo-ny-loft-recommender-2019-08-20-03-05-18-645', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[31m[08/20/2019 03:08:02 INFO 140399032596288] envs={'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/8bf00102-0f0e-4952-857a-ed2435e941c6', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'DMLC_NUM_WORKER': '4', 'DMLC_PS_ROOT_PORT': '9000', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'DMLC_PS_ROOT_URI': '10.0.157.195', 'AWS_REGION': 'us-west-2', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'DEMO-ny-loft-recommender-2019-08-20-03-05-18-645', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '4', 'HOSTNAME': 'ip-10-0-157-195.us-west-2.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/39c636a8-c8d9-4e60-bb91-dd2a206306af', 'DMLC_ROLE': 'scheduler', 'PWD': '/', 'DMLC_NUM_SERVER': '4', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-west-2:453691756499:training-job/demo-ny-loft-recommender-2019-08-20-03-05-18-645', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[31m[08/20/2019 03:08:02 INFO 140399032596288] Launching parameter server for role server\u001b[0m\n",
      "\u001b[31m[08/20/2019 03:08:02 INFO 140399032596288] {'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/8bf00102-0f0e-4952-857a-ed2435e941c6', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'AWS_REGION': 'us-west-2', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'DEMO-ny-loft-recommender-2019-08-20-03-05-18-645', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '4', 'HOSTNAME': 'ip-10-0-157-195.us-west-2.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/39c636a8-c8d9-4e60-bb91-dd2a206306af', 'PWD': '/', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-west-2:453691756499:training-job/demo-ny-loft-recommender-2019-08-20-03-05-18-645', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[31m[08/20/2019 03:08:02 INFO 140399032596288] envs={'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/8bf00102-0f0e-4952-857a-ed2435e941c6', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'DMLC_NUM_WORKER': '4', 'DMLC_PS_ROOT_PORT': '9000', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'DMLC_PS_ROOT_URI': '10.0.157.195', 'AWS_REGION': 'us-west-2', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'DEMO-ny-loft-recommender-2019-08-20-03-05-18-645', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '4', 'HOSTNAME': 'ip-10-0-157-195.us-west-2.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/39c636a8-c8d9-4e60-bb91-dd2a206306af', 'DMLC_ROLE': 'server', 'PWD': '/', 'DMLC_NUM_SERVER': '4', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-west-2:453691756499:training-job/demo-ny-loft-recommender-2019-08-20-03-05-18-645', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[31m[08/20/2019 03:08:02 INFO 140399032596288] Environment: {'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/8bf00102-0f0e-4952-857a-ed2435e941c6', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'DMLC_PS_ROOT_PORT': '9000', 'DMLC_NUM_WORKER': '4', 'SAGEMAKER_HTTP_PORT': '8080', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'DMLC_PS_ROOT_URI': '10.0.157.195', 'AWS_REGION': 'us-west-2', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'DEMO-ny-loft-recommender-2019-08-20-03-05-18-645', 'HOME': '/root', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '4', 'HOSTNAME': 'ip-10-0-157-195.us-west-2.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/39c636a8-c8d9-4e60-bb91-dd2a206306af', 'DMLC_ROLE': 'worker', 'PWD': '/', 'DMLC_NUM_SERVER': '4', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-west-2:453691756499:training-job/demo-ny-loft-recommender-2019-08-20-03-05-18-645', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[31mProcess 39 is a shell:scheduler.\u001b[0m\n",
      "\u001b[31mProcess 40 is a shell:server.\u001b[0m\n",
      "\u001b[31mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[31m[08/20/2019 03:08:02 INFO 140399032596288] Using default worker.\u001b[0m\n",
      "\u001b[31m[2019-08-20 03:08:02.246] [tensorio] [warning] TensorIO is already initialized; ignoring the initialization routine.\u001b[0m\n",
      "\u001b[31m[2019-08-20 03:08:02.252] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 10, \"num_examples\": 1, \"num_bytes\": 71592}\u001b[0m\n",
      "\u001b[31m[08/20/2019 03:08:02 INFO 140399032596288] nvidia-smi took: 0.0251581668854 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[31m[08/20/2019 03:08:02 INFO 140399032596288] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[31m[08/20/2019 03:08:02 INFO 140399032596288] [Sparse network] Building a sparse network.\u001b[0m\n",
      "\u001b[31m[08/20/2019 03:08:02 INFO 140399032596288] Create Store: dist_async\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 835.8480930328369, \"sum\": 835.8480930328369, \"min\": 835.8480930328369}}, \"EndTime\": 1566270483.086506, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1566270482.241436}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Total Records Seen\": {\"count\": 1, \"max\": 1000, \"sum\": 1000.0, \"min\": 1000}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1000, \"sum\": 1000.0, \"min\": 1000}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1566270483.086678, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1566270483.086645}\n",
      "\u001b[0m\n",
      "\u001b[32m[08/20/2019 03:08:02 INFO 139979787347776] nvidia-smi took: 0.0251150131226 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[32m[08/20/2019 03:08:02 INFO 139979787347776] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[32m[08/20/2019 03:08:02 INFO 139979787347776] [Sparse network] Building a sparse network.\u001b[0m\n",
      "\u001b[32m[08/20/2019 03:08:02 INFO 139979787347776] Create Store: dist_async\u001b[0m\n",
      "\u001b[32m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 404.6649932861328, \"sum\": 404.6649932861328, \"min\": 404.6649932861328}}, \"EndTime\": 1566270483.08744, \"Dimensions\": {\"Host\": \"algo-2\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1566270482.674725}\n",
      "\u001b[0m\n",
      "\u001b[32m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Total Records Seen\": {\"count\": 1, \"max\": 1000, \"sum\": 1000.0, \"min\": 1000}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1000, \"sum\": 1000.0, \"min\": 1000}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1566270483.087602, \"Dimensions\": {\"Host\": \"algo-2\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1566270483.087569}\n",
      "\u001b[0m\n",
      "\u001b[33m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 702.1229267120361, \"sum\": 702.1229267120361, \"min\": 702.1229267120361}}, \"EndTime\": 1566270483.084812, \"Dimensions\": {\"Host\": \"algo-3\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1566270482.374968}\n",
      "\u001b[0m\n",
      "\u001b[33m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Total Records Seen\": {\"count\": 1, \"max\": 1000, \"sum\": 1000.0, \"min\": 1000}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1000, \"sum\": 1000.0, \"min\": 1000}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1566270483.084979, \"Dimensions\": {\"Host\": \"algo-3\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1566270483.084947}\n",
      "\u001b[0m\n",
      "\u001b[33m[03:08:03] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.1.x.201927.0/RHEL5_64/generic-flavor/src/src/kvstore/./kvstore_local.h:280: Warning: non-default weights detected during kvstore pull. This call has been ignored. Please make sure to use row_sparse_pull with row_ids.\u001b[0m\n",
      "\u001b[31m[03:08:03] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.1.x.201927.0/RHEL5_64/generic-flavor/src/src/kvstore/./kvstore_local.h:280: Warning: non-default weights detected during kvstore pull. This call has been ignored. Please make sure to use row_sparse_pull with row_ids.\u001b[0m\n",
      "\u001b[31m[03:08:04] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.1.x.201927.0/RHEL5_64/generic-flavor/src/src/kvstore/./kvstore_local.h:280: Warning: non-default weights detected during kvstore pull. This call has been ignored. Please make sure to use row_sparse_pull with row_ids.\u001b[0m\n",
      "\u001b[31m[08/20/2019 03:08:04 INFO 140399032596288] #quality_metric: host=algo-1, epoch=0, batch=0 train rmse <loss>=4.48608395137\u001b[0m\n",
      "\u001b[31m[08/20/2019 03:08:04 INFO 140399032596288] #quality_metric: host=algo-1, epoch=0, batch=0 train mse <loss>=20.1249492188\u001b[0m\n",
      "\u001b[31m[08/20/2019 03:08:04 INFO 140399032596288] #quality_metric: host=algo-1, epoch=0, batch=0 train absolute_loss <loss>=4.37487792969\u001b[0m\n",
      "\u001b[32m[03:08:03] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.1.x.201927.0/RHEL5_64/generic-flavor/src/src/kvstore/./kvstore_local.h:280: Warning: non-default weights detected during kvstore pull. This call has been ignored. Please make sure to use row_sparse_pull with row_ids.\u001b[0m\n",
      "\u001b[32m[03:08:04] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.1.x.201927.0/RHEL5_64/generic-flavor/src/src/kvstore/./kvstore_local.h:280: Warning: non-default weights detected during kvstore pull. This call has been ignored. Please make sure to use row_sparse_pull with row_ids.\u001b[0m\n",
      "\u001b[32m[08/20/2019 03:08:04 INFO 139979787347776] #quality_metric: host=algo-2, epoch=0, batch=0 train rmse <loss>=4.24214531517\u001b[0m\n",
      "\u001b[32m[08/20/2019 03:08:04 INFO 139979787347776] #quality_metric: host=algo-2, epoch=0, batch=0 train mse <loss>=17.995796875\u001b[0m\n",
      "\u001b[32m[08/20/2019 03:08:04 INFO 139979787347776] #quality_metric: host=algo-2, epoch=0, batch=0 train absolute_loss <loss>=4.06187792969\u001b[0m\n",
      "\u001b[33m[03:08:04] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.1.x.201927.0/RHEL5_64/generic-flavor/src/src/kvstore/./kvstore_local.h:280: Warning: non-default weights detected during kvstore pull. This call has been ignored. Please make sure to use row_sparse_pull with row_ids.\u001b[0m\n",
      "\u001b[33m[08/20/2019 03:08:04 INFO 140385400035136] #quality_metric: host=algo-3, epoch=0, batch=0 train rmse <loss>=4.43319046899\u001b[0m\n",
      "\u001b[33m[08/20/2019 03:08:04 INFO 140385400035136] #quality_metric: host=algo-3, epoch=0, batch=0 train mse <loss>=19.6531777344\u001b[0m\n",
      "\u001b[33m[08/20/2019 03:08:04 INFO 140385400035136] #quality_metric: host=algo-3, epoch=0, batch=0 train absolute_loss <loss>=4.30187792969\u001b[0m\n",
      "\n",
      "2019-08-20 03:07:59 Training - Training image download completed. Training in progress.\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python2.7/site-packages/pandas/util/nosetester.py:13: DeprecationWarning: Importing from numpy.testing.nosetester is deprecated, import from numpy.testing instead.\n",
      "  from numpy.testing import nosetester\u001b[0m\n",
      "\u001b[34m[08/20/2019 03:08:00 INFO 139675139647296] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-conf.json: {u'factors_lr': u'0.0001', u'linear_init_sigma': u'0.01', u'epochs': 1, u'_wd': u'1.0', u'_num_kv_servers': u'auto', u'use_bias': u'true', u'factors_init_sigma': u'0.001', u'_log_level': u'info', u'bias_init_method': u'normal', u'linear_init_method': u'normal', u'linear_lr': u'0.001', u'factors_init_method': u'normal', u'_tuning_objective_metric': u'', u'bias_wd': u'0.01', u'use_linear': u'true', u'bias_lr': u'0.1', u'mini_batch_size': u'1000', u'_use_full_symbolic': u'true', u'batch_metrics_publish_interval': u'500', u'bias_init_sigma': u'0.01', u'_num_gpus': u'auto', u'_data_format': u'record', u'factors_wd': u'0.00001', u'linear_wd': u'0.001', u'_kvstore': u'auto', u'_learning_rate': u'1.0', u'_optimizer': u'adam'}\u001b[0m\n",
      "\u001b[34m[08/20/2019 03:08:00 INFO 139675139647296] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'epochs': u'3', u'feature_dim': u'178730', u'mini_batch_size': u'1000', u'predictor_type': u'regressor', u'num_factors': u'256'}\u001b[0m\n",
      "\u001b[34m[08/20/2019 03:08:00 INFO 139675139647296] Final configuration: {u'factors_lr': u'0.0001', u'linear_init_sigma': u'0.01', u'epochs': u'3', u'feature_dim': u'178730', u'num_factors': u'256', u'_wd': u'1.0', u'_num_kv_servers': u'auto', u'use_bias': u'true', u'factors_init_sigma': u'0.001', u'_log_level': u'info', u'bias_init_method': u'normal', u'linear_init_method': u'normal', u'linear_lr': u'0.001', u'factors_init_method': u'normal', u'_tuning_objective_metric': u'', u'bias_wd': u'0.01', u'use_linear': u'true', u'bias_lr': u'0.1', u'mini_batch_size': u'1000', u'_use_full_symbolic': u'true', u'batch_metrics_publish_interval': u'500', u'predictor_type': u'regressor', u'bias_init_sigma': u'0.01', u'_num_gpus': u'auto', u'_data_format': u'record', u'factors_wd': u'0.00001', u'linear_wd': u'0.001', u'_kvstore': u'auto', u'_learning_rate': u'1.0', u'_optimizer': u'adam'}\u001b[0m\n",
      "\u001b[34m[08/20/2019 03:08:00 WARNING 139675139647296] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34m[08/20/2019 03:08:02 INFO 139675139647296] Launching parameter server for role server\u001b[0m\n",
      "\u001b[34m[08/20/2019 03:08:02 INFO 139675139647296] {'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/33eb7a4a-e78c-46cd-8b59-e05d6d9ff857', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'AWS_REGION': 'us-west-2', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'DEMO-ny-loft-recommender-2019-08-20-03-05-18-645', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '4', 'HOSTNAME': 'ip-10-0-185-37.us-west-2.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/308b682c-265f-49a5-b234-20311b0ab646', 'PWD': '/', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-west-2:453691756499:training-job/demo-ny-loft-recommender-2019-08-20-03-05-18-645', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34m[08/20/2019 03:08:02 INFO 139675139647296] envs={'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/33eb7a4a-e78c-46cd-8b59-e05d6d9ff857', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'DMLC_NUM_WORKER': '4', 'DMLC_PS_ROOT_PORT': '9000', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'DMLC_PS_ROOT_URI': '10.0.157.195', 'AWS_REGION': 'us-west-2', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'DEMO-ny-loft-recommender-2019-08-20-03-05-18-645', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '4', 'HOSTNAME': 'ip-10-0-185-37.us-west-2.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/308b682c-265f-49a5-b234-20311b0ab646', 'DMLC_ROLE': 'server', 'PWD': '/', 'DMLC_NUM_SERVER': '4', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-west-2:453691756499:training-job/demo-ny-loft-recommender-2019-08-20-03-05-18-645', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34m[08/20/2019 03:08:02 INFO 139675139647296] Environment: {'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/33eb7a4a-e78c-46cd-8b59-e05d6d9ff857', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'DMLC_PS_ROOT_PORT': '9000', 'DMLC_NUM_WORKER': '4', 'SAGEMAKER_HTTP_PORT': '8080', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'DMLC_PS_ROOT_URI': '10.0.157.195', 'AWS_REGION': 'us-west-2', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'DEMO-ny-loft-recommender-2019-08-20-03-05-18-645', 'HOME': '/root', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '4', 'HOSTNAME': 'ip-10-0-185-37.us-west-2.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/308b682c-265f-49a5-b234-20311b0ab646', 'DMLC_ROLE': 'worker', 'PWD': '/', 'DMLC_NUM_SERVER': '4', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-west-2:453691756499:training-job/demo-ny-loft-recommender-2019-08-20-03-05-18-645', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34mProcess 39 is a shell:server.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[08/20/2019 03:08:02 INFO 139675139647296] Using default worker.\u001b[0m\n",
      "\u001b[34m[2019-08-20 03:08:02.423] [tensorio] [warning] TensorIO is already initialized; ignoring the initialization routine.\u001b[0m\n",
      "\u001b[34m[2019-08-20 03:08:02.429] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 11, \"num_examples\": 1, \"num_bytes\": 71496}\u001b[0m\n",
      "\u001b[34m[08/20/2019 03:08:02 INFO 139675139647296] nvidia-smi took: 0.0251288414001 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[08/20/2019 03:08:02 INFO 139675139647296] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[08/20/2019 03:08:02 INFO 139675139647296] [Sparse network] Building a sparse network.\u001b[0m\n",
      "\u001b[34m[08/20/2019 03:08:02 INFO 139675139647296] Create Store: dist_async\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 660.789966583252, \"sum\": 660.789966583252, \"min\": 660.789966583252}}, \"EndTime\": 1566270483.087346, \"Dimensions\": {\"Host\": \"algo-4\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1566270482.417564}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Total Records Seen\": {\"count\": 1, \"max\": 1000, \"sum\": 1000.0, \"min\": 1000}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1000, \"sum\": 1000.0, \"min\": 1000}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1566270483.08754, \"Dimensions\": {\"Host\": \"algo-4\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1566270483.087496}\n",
      "\u001b[0m\n",
      "\u001b[34m[03:08:03] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.1.x.201927.0/RHEL5_64/generic-flavor/src/src/kvstore/./kvstore_local.h:280: Warning: non-default weights detected during kvstore pull. This call has been ignored. Please make sure to use row_sparse_pull with row_ids.\u001b[0m\n",
      "\u001b[34m[03:08:04] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.1.x.201927.0/RHEL5_64/generic-flavor/src/src/kvstore/./kvstore_local.h:280: Warning: non-default weights detected during kvstore pull. This call has been ignored. Please make sure to use row_sparse_pull with row_ids.\u001b[0m\n",
      "\u001b[34m[08/20/2019 03:08:04 INFO 139675139647296] #quality_metric: host=algo-4, epoch=0, batch=0 train rmse <loss>=4.15243716087\u001b[0m\n",
      "\u001b[34m[08/20/2019 03:08:04 INFO 139675139647296] #quality_metric: host=algo-4, epoch=0, batch=0 train mse <loss>=17.242734375\u001b[0m\n",
      "\u001b[34m[08/20/2019 03:08:04 INFO 139675139647296] #quality_metric: host=algo-4, epoch=0, batch=0 train absolute_loss <loss>=3.97287792969\u001b[0m\n",
      "\u001b[33m[2019-08-20 03:08:06.942] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 2, \"duration\": 2847, \"num_examples\": 206, \"num_bytes\": 14630020}\u001b[0m\n",
      "\u001b[33m[08/20/2019 03:08:06 INFO 140385400035136] #quality_metric: host=algo-3, epoch=0, train rmse <loss>=1.34528841085\u001b[0m\n",
      "\u001b[33m[08/20/2019 03:08:06 INFO 140385400035136] #quality_metric: host=algo-3, epoch=0, train mse <loss>=1.80980090836\u001b[0m\n",
      "\u001b[33m[08/20/2019 03:08:06 INFO 140385400035136] #quality_metric: host=algo-3, epoch=0, train absolute_loss <loss>=1.04099728305\u001b[0m\n",
      "\u001b[33m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 3, \"sum\": 3.0, \"min\": 3}, \"update.time\": {\"count\": 1, \"max\": 3858.1650257110596, \"sum\": 3858.1650257110596, \"min\": 3858.1650257110596}}, \"EndTime\": 1566270486.943302, \"Dimensions\": {\"Host\": \"algo-3\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1566270483.084894}\n",
      "\u001b[0m\n",
      "\u001b[33m[08/20/2019 03:08:06 INFO 140385400035136] #progress_metric: host=algo-3, completed 33 % of epochs\u001b[0m\n",
      "\u001b[33m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 206, \"sum\": 206.0, \"min\": 206}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 206, \"sum\": 206.0, \"min\": 206}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 205721, \"sum\": 205721.0, \"min\": 205721}, \"Total Batches Seen\": {\"count\": 1, \"max\": 207, \"sum\": 207.0, \"min\": 207}, \"Total Records Seen\": {\"count\": 1, \"max\": 206721, \"sum\": 206721.0, \"min\": 206721}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 205721, \"sum\": 205721.0, \"min\": 205721}, \"Reset Count\": {\"count\": 1, \"max\": 2, \"sum\": 2.0, \"min\": 2}}, \"EndTime\": 1566270486.943464, \"Dimensions\": {\"Host\": \"algo-3\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 0}, \"StartTime\": 1566270483.085113}\n",
      "\u001b[0m\n",
      "\u001b[33m[08/20/2019 03:08:06 INFO 140385400035136] #throughput_metric: host=algo-3, train throughput=53317.4050595 records/second\u001b[0m\n",
      "\u001b[34m[2019-08-20 03:08:06.848] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 2, \"duration\": 2751, \"num_examples\": 206, \"num_bytes\": 14622296}\u001b[0m\n",
      "\u001b[34m[08/20/2019 03:08:06 INFO 139675139647296] #quality_metric: host=algo-4, epoch=0, train rmse <loss>=1.31919110405\u001b[0m\n",
      "\u001b[34m[08/20/2019 03:08:06 INFO 139675139647296] #quality_metric: host=algo-4, epoch=0, train mse <loss>=1.74026516901\u001b[0m\n",
      "\u001b[34m[08/20/2019 03:08:06 INFO 139675139647296] #quality_metric: host=algo-4, epoch=0, train absolute_loss <loss>=1.02700017896\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 3, \"sum\": 3.0, \"min\": 3}, \"update.time\": {\"count\": 1, \"max\": 3761.590003967285, \"sum\": 3761.590003967285, \"min\": 3761.590003967285}}, \"EndTime\": 1566270486.849304, \"Dimensions\": {\"Host\": \"algo-4\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1566270483.087433}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/20/2019 03:08:06 INFO 139675139647296] #progress_metric: host=algo-4, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 206, \"sum\": 206.0, \"min\": 206}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 206, \"sum\": 206.0, \"min\": 206}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 205721, \"sum\": 205721.0, \"min\": 205721}, \"Total Batches Seen\": {\"count\": 1, \"max\": 207, \"sum\": 207.0, \"min\": 207}, \"Total Records Seen\": {\"count\": 1, \"max\": 206721, \"sum\": 206721.0, \"min\": 206721}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 205721, \"sum\": 205721.0, \"min\": 205721}, \"Reset Count\": {\"count\": 1, \"max\": 2, \"sum\": 2.0, \"min\": 2}}, \"EndTime\": 1566270486.84948, \"Dimensions\": {\"Host\": \"algo-4\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 0}, \"StartTime\": 1566270483.087686}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/20/2019 03:08:06 INFO 139675139647296] #throughput_metric: host=algo-4, train throughput=54685.7179461 records/second\u001b[0m\n",
      "\u001b[34m[08/20/2019 03:08:06 INFO 139675139647296] #quality_metric: host=algo-4, epoch=1, batch=0 train rmse <loss>=1.20872731768\u001b[0m\n",
      "\u001b[34m[08/20/2019 03:08:06 INFO 139675139647296] #quality_metric: host=algo-4, epoch=1, batch=0 train mse <loss>=1.46102172852\u001b[0m\n",
      "\u001b[34m[08/20/2019 03:08:06 INFO 139675139647296] #quality_metric: host=algo-4, epoch=1, batch=0 train absolute_loss <loss>=0.950210998535\u001b[0m\n",
      "\u001b[33m[08/20/2019 03:08:06 INFO 140385400035136] #quality_metric: host=algo-3, epoch=1, batch=0 train rmse <loss>=1.129427972\u001b[0m\n",
      "\u001b[33m[08/20/2019 03:08:06 INFO 140385400035136] #quality_metric: host=algo-3, epoch=1, batch=0 train mse <loss>=1.27560754395\u001b[0m\n",
      "\u001b[33m[08/20/2019 03:08:06 INFO 140385400035136] #quality_metric: host=algo-3, epoch=1, batch=0 train absolute_loss <loss>=0.931379760742\u001b[0m\n",
      "\u001b[32m[2019-08-20 03:08:08.609] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 2, \"duration\": 4512, \"num_examples\": 309, \"num_bytes\": 21931124}\u001b[0m\n",
      "\u001b[32m[08/20/2019 03:08:08 INFO 139979787347776] #quality_metric: host=algo-2, epoch=0, train rmse <loss>=1.31197561166\u001b[0m\n",
      "\u001b[32m[08/20/2019 03:08:08 INFO 139979787347776] #quality_metric: host=algo-2, epoch=0, train mse <loss>=1.72128000559\u001b[0m\n",
      "\u001b[32m[08/20/2019 03:08:08 INFO 139979787347776] #quality_metric: host=algo-2, epoch=0, train absolute_loss <loss>=1.02028223604\u001b[0m\n",
      "\u001b[32m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 3, \"sum\": 3.0, \"min\": 3}, \"update.time\": {\"count\": 1, \"max\": 5522.636890411377, \"sum\": 5522.636890411377, \"min\": 5522.636890411377}}, \"EndTime\": 1566270488.610377, \"Dimensions\": {\"Host\": \"algo-2\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1566270483.08752}\n",
      "\u001b[0m\n",
      "\u001b[32m[08/20/2019 03:08:08 INFO 139979787347776] #progress_metric: host=algo-2, completed 33 % of epochs\u001b[0m\n",
      "\u001b[32m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 309, \"sum\": 309.0, \"min\": 309}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 309, \"sum\": 309.0, \"min\": 309}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 308582, \"sum\": 308582.0, \"min\": 308582}, \"Total Batches Seen\": {\"count\": 1, \"max\": 310, \"sum\": 310.0, \"min\": 310}, \"Total Records Seen\": {\"count\": 1, \"max\": 309582, \"sum\": 309582.0, \"min\": 309582}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 308582, \"sum\": 308582.0, \"min\": 308582}, \"Reset Count\": {\"count\": 1, \"max\": 2, \"sum\": 2.0, \"min\": 2}}, \"EndTime\": 1566270488.610541, \"Dimensions\": {\"Host\": \"algo-2\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 0}, \"StartTime\": 1566270483.087717}\n",
      "\u001b[0m\n",
      "\u001b[32m[08/20/2019 03:08:08 INFO 139979787347776] #throughput_metric: host=algo-2, train throughput=55873.2321616 records/second\u001b[0m\n",
      "\u001b[32m[08/20/2019 03:08:08 INFO 139979787347776] #quality_metric: host=algo-2, epoch=1, batch=0 train rmse <loss>=1.2346408436\u001b[0m\n",
      "\u001b[32m[08/20/2019 03:08:08 INFO 139979787347776] #quality_metric: host=algo-2, epoch=1, batch=0 train mse <loss>=1.5243380127\u001b[0m\n",
      "\u001b[32m[08/20/2019 03:08:08 INFO 139979787347776] #quality_metric: host=algo-2, epoch=1, batch=0 train absolute_loss <loss>=0.991853210449\u001b[0m\n",
      "\u001b[31m[2019-08-20 03:08:08.590] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 2, \"duration\": 4493, \"num_examples\": 309, \"num_bytes\": 21961380}\u001b[0m\n",
      "\u001b[31m[08/20/2019 03:08:08 INFO 140399032596288] #quality_metric: host=algo-1, epoch=0, train rmse <loss>=1.32196968679\u001b[0m\n",
      "\u001b[31m[08/20/2019 03:08:08 INFO 140399032596288] #quality_metric: host=algo-1, epoch=0, train mse <loss>=1.7476038528\u001b[0m\n",
      "\u001b[31m[08/20/2019 03:08:08 INFO 140399032596288] #quality_metric: host=algo-1, epoch=0, train absolute_loss <loss>=1.02206002166\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 3, \"sum\": 3.0, \"min\": 3}, \"update.time\": {\"count\": 1, \"max\": 5504.106044769287, \"sum\": 5504.106044769287, \"min\": 5504.106044769287}}, \"EndTime\": 1566270488.590939, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1566270483.086587}\n",
      "\u001b[0m\n",
      "\u001b[31m[08/20/2019 03:08:08 INFO 140399032596288] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 309, \"sum\": 309.0, \"min\": 309}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 309, \"sum\": 309.0, \"min\": 309}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 308582, \"sum\": 308582.0, \"min\": 308582}, \"Total Batches Seen\": {\"count\": 1, \"max\": 310, \"sum\": 310.0, \"min\": 310}, \"Total Records Seen\": {\"count\": 1, \"max\": 309582, \"sum\": 309582.0, \"min\": 309582}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 308582, \"sum\": 308582.0, \"min\": 308582}, \"Reset Count\": {\"count\": 1, \"max\": 2, \"sum\": 2.0, \"min\": 2}}, \"EndTime\": 1566270488.591117, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 0}, \"StartTime\": 1566270483.086808}\n",
      "\u001b[0m\n",
      "\u001b[31m[08/20/2019 03:08:08 INFO 140399032596288] #throughput_metric: host=algo-1, train throughput=56061.1950815 records/second\u001b[0m\n",
      "\u001b[31m[08/20/2019 03:08:08 INFO 140399032596288] #quality_metric: host=algo-1, epoch=1, batch=0 train rmse <loss>=1.05484715227\u001b[0m\n",
      "\u001b[31m[08/20/2019 03:08:08 INFO 140399032596288] #quality_metric: host=algo-1, epoch=1, batch=0 train mse <loss>=1.11270251465\u001b[0m\n",
      "\u001b[31m[08/20/2019 03:08:08 INFO 140399032596288] #quality_metric: host=algo-1, epoch=1, batch=0 train absolute_loss <loss>=0.877504943848\u001b[0m\n",
      "\u001b[34m[2019-08-20 03:08:09.350] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 4, \"duration\": 2499, \"num_examples\": 206, \"num_bytes\": 14622296}\u001b[0m\n",
      "\u001b[34m[08/20/2019 03:08:09 INFO 139675139647296] #quality_metric: host=algo-4, epoch=1, train rmse <loss>=1.19901814869\u001b[0m\n",
      "\u001b[34m[08/20/2019 03:08:09 INFO 139675139647296] #quality_metric: host=algo-4, epoch=1, train mse <loss>=1.43764452088\u001b[0m\n",
      "\u001b[34m[08/20/2019 03:08:09 INFO 139675139647296] #quality_metric: host=algo-4, epoch=1, train absolute_loss <loss>=0.953079484662\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2501.668930053711, \"sum\": 2501.668930053711, \"min\": 2501.668930053711}}, \"EndTime\": 1566270489.351368, \"Dimensions\": {\"Host\": \"algo-4\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1566270486.849374}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/20/2019 03:08:09 INFO 139675139647296] #progress_metric: host=algo-4, completed 66 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 206, \"sum\": 206.0, \"min\": 206}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 206, \"sum\": 206.0, \"min\": 206}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 205721, \"sum\": 205721.0, \"min\": 205721}, \"Total Batches Seen\": {\"count\": 1, \"max\": 413, \"sum\": 413.0, \"min\": 413}, \"Total Records Seen\": {\"count\": 1, \"max\": 412442, \"sum\": 412442.0, \"min\": 412442}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 205721, \"sum\": 205721.0, \"min\": 205721}, \"Reset Count\": {\"count\": 1, \"max\": 3, \"sum\": 3.0, \"min\": 3}}, \"EndTime\": 1566270489.351519, \"Dimensions\": {\"Host\": \"algo-4\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 1}, \"StartTime\": 1566270486.849671}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/20/2019 03:08:09 INFO 139675139647296] #throughput_metric: host=algo-4, train throughput=82224.5619798 records/second\u001b[0m\n",
      "\u001b[34m[08/20/2019 03:08:09 INFO 139675139647296] #quality_metric: host=algo-4, epoch=2, batch=0 train rmse <loss>=1.20878195246\u001b[0m\n",
      "\u001b[34m[08/20/2019 03:08:09 INFO 139675139647296] #quality_metric: host=algo-4, epoch=2, batch=0 train mse <loss>=1.46115380859\u001b[0m\n",
      "\u001b[34m[08/20/2019 03:08:09 INFO 139675139647296] #quality_metric: host=algo-4, epoch=2, batch=0 train absolute_loss <loss>=0.950875183105\u001b[0m\n",
      "\u001b[33m[2019-08-20 03:08:09.490] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 4, \"duration\": 2545, \"num_examples\": 206, \"num_bytes\": 14630020}\u001b[0m\n",
      "\u001b[33m[08/20/2019 03:08:09 INFO 140385400035136] #quality_metric: host=algo-3, epoch=1, train rmse <loss>=1.19001306502\u001b[0m\n",
      "\u001b[33m[08/20/2019 03:08:09 INFO 140385400035136] #quality_metric: host=algo-3, epoch=1, train mse <loss>=1.41613109492\u001b[0m\n",
      "\u001b[33m[08/20/2019 03:08:09 INFO 140385400035136] #quality_metric: host=algo-3, epoch=1, train absolute_loss <loss>=0.950651706436\u001b[0m\n",
      "\u001b[33m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2547.7230548858643, \"sum\": 2547.7230548858643, \"min\": 2547.7230548858643}}, \"EndTime\": 1566270489.491376, \"Dimensions\": {\"Host\": \"algo-3\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1566270486.943372}\n",
      "\u001b[0m\n",
      "\u001b[33m[08/20/2019 03:08:09 INFO 140385400035136] #progress_metric: host=algo-3, completed 66 % of epochs\u001b[0m\n",
      "\u001b[33m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 206, \"sum\": 206.0, \"min\": 206}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 206, \"sum\": 206.0, \"min\": 206}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 205721, \"sum\": 205721.0, \"min\": 205721}, \"Total Batches Seen\": {\"count\": 1, \"max\": 413, \"sum\": 413.0, \"min\": 413}, \"Total Records Seen\": {\"count\": 1, \"max\": 412442, \"sum\": 412442.0, \"min\": 412442}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 205721, \"sum\": 205721.0, \"min\": 205721}, \"Reset Count\": {\"count\": 1, \"max\": 3, \"sum\": 3.0, \"min\": 3}}, \"EndTime\": 1566270489.491545, \"Dimensions\": {\"Host\": \"algo-3\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 1}, \"StartTime\": 1566270486.943626}\n",
      "\u001b[0m\n",
      "\u001b[33m[08/20/2019 03:08:09 INFO 140385400035136] #throughput_metric: host=algo-3, train throughput=80738.0945468 records/second\u001b[0m\n",
      "\u001b[33m[08/20/2019 03:08:09 INFO 140385400035136] #quality_metric: host=algo-3, epoch=2, batch=0 train rmse <loss>=1.12534033481\u001b[0m\n",
      "\u001b[33m[08/20/2019 03:08:09 INFO 140385400035136] #quality_metric: host=algo-3, epoch=2, batch=0 train mse <loss>=1.26639086914\u001b[0m\n",
      "\u001b[33m[08/20/2019 03:08:09 INFO 140385400035136] #quality_metric: host=algo-3, epoch=2, batch=0 train absolute_loss <loss>=0.922530700684\u001b[0m\n",
      "\u001b[34m[2019-08-20 03:08:11.820] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 6, \"duration\": 2467, \"num_examples\": 206, \"num_bytes\": 14622296}\u001b[0m\n",
      "\u001b[34m[08/20/2019 03:08:11 INFO 139675139647296] #quality_metric: host=algo-4, epoch=2, train rmse <loss>=1.2092161462\u001b[0m\n",
      "\u001b[34m[08/20/2019 03:08:11 INFO 139675139647296] #quality_metric: host=algo-4, epoch=2, train mse <loss>=1.46220368824\u001b[0m\n",
      "\u001b[34m[08/20/2019 03:08:11 INFO 139675139647296] #quality_metric: host=algo-4, epoch=2, train absolute_loss <loss>=0.967480786074\u001b[0m\n",
      "\u001b[34m[08/20/2019 03:08:11 INFO 139675139647296] #quality_metric: host=algo-4, train rmse <loss>=1.2092161462\u001b[0m\n",
      "\u001b[34m[08/20/2019 03:08:11 INFO 139675139647296] #quality_metric: host=algo-4, train mse <loss>=1.46220368824\u001b[0m\n",
      "\u001b[34m[08/20/2019 03:08:11 INFO 139675139647296] #quality_metric: host=algo-4, train absolute_loss <loss>=0.967480786074\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2469.578981399536, \"sum\": 2469.578981399536, \"min\": 2469.578981399536}}, \"EndTime\": 1566270491.821281, \"Dimensions\": {\"Host\": \"algo-4\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1566270489.35143}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/20/2019 03:08:11 INFO 139675139647296] #progress_metric: host=algo-4, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 206, \"sum\": 206.0, \"min\": 206}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 206, \"sum\": 206.0, \"min\": 206}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 205721, \"sum\": 205721.0, \"min\": 205721}, \"Total Batches Seen\": {\"count\": 1, \"max\": 619, \"sum\": 619.0, \"min\": 619}, \"Total Records Seen\": {\"count\": 1, \"max\": 618163, \"sum\": 618163.0, \"min\": 618163}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 205721, \"sum\": 205721.0, \"min\": 205721}, \"Reset Count\": {\"count\": 1, \"max\": 4, \"sum\": 4.0, \"min\": 4}}, \"EndTime\": 1566270491.821427, \"Dimensions\": {\"Host\": \"algo-4\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 2}, \"StartTime\": 1566270489.351678}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/20/2019 03:08:11 INFO 139675139647296] #throughput_metric: host=algo-4, train throughput=83293.4490997 records/second\u001b[0m\n",
      "\u001b[32m[2019-08-20 03:08:12.678] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 4, \"duration\": 4066, \"num_examples\": 309, \"num_bytes\": 21931124}\u001b[0m\n",
      "\u001b[32m[08/20/2019 03:08:12 INFO 139979787347776] #quality_metric: host=algo-2, epoch=1, train rmse <loss>=1.22696054286\u001b[0m\n",
      "\u001b[32m[08/20/2019 03:08:12 INFO 139979787347776] #quality_metric: host=algo-2, epoch=1, train mse <loss>=1.50543217374\u001b[0m\n",
      "\u001b[32m[08/20/2019 03:08:12 INFO 139979787347776] #quality_metric: host=algo-2, epoch=1, train absolute_loss <loss>=0.978108800203\u001b[0m\n",
      "\u001b[32m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4068.4430599212646, \"sum\": 4068.4430599212646, \"min\": 4068.4430599212646}}, \"EndTime\": 1566270492.679166, \"Dimensions\": {\"Host\": \"algo-2\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1566270488.610445}\n",
      "\u001b[0m\n",
      "\u001b[32m[08/20/2019 03:08:12 INFO 139979787347776] #progress_metric: host=algo-2, completed 66 % of epochs\u001b[0m\n",
      "\u001b[32m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 309, \"sum\": 309.0, \"min\": 309}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 309, \"sum\": 309.0, \"min\": 309}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 308582, \"sum\": 308582.0, \"min\": 308582}, \"Total Batches Seen\": {\"count\": 1, \"max\": 619, \"sum\": 619.0, \"min\": 619}, \"Total Records Seen\": {\"count\": 1, \"max\": 618164, \"sum\": 618164.0, \"min\": 618164}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 308582, \"sum\": 308582.0, \"min\": 308582}, \"Reset Count\": {\"count\": 1, \"max\": 3, \"sum\": 3.0, \"min\": 3}}, \"EndTime\": 1566270492.679306, \"Dimensions\": {\"Host\": \"algo-2\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 1}, \"StartTime\": 1566270488.610699}\n",
      "\u001b[0m\n",
      "\u001b[32m[08/20/2019 03:08:12 INFO 139979787347776] #throughput_metric: host=algo-2, train throughput=75842.9723747 records/second\u001b[0m\n",
      "\u001b[33m[2019-08-20 03:08:11.998] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 6, \"duration\": 2505, \"num_examples\": 206, \"num_bytes\": 14630020}\u001b[0m\n",
      "\u001b[33m[08/20/2019 03:08:11 INFO 140385400035136] #quality_metric: host=algo-3, epoch=2, train rmse <loss>=1.19511727467\u001b[0m\n",
      "\u001b[33m[08/20/2019 03:08:11 INFO 140385400035136] #quality_metric: host=algo-3, epoch=2, train mse <loss>=1.42830530022\u001b[0m\n",
      "\u001b[33m[08/20/2019 03:08:11 INFO 140385400035136] #quality_metric: host=algo-3, epoch=2, train absolute_loss <loss>=0.957702086217\u001b[0m\n",
      "\u001b[33m[08/20/2019 03:08:11 INFO 140385400035136] #quality_metric: host=algo-3, train rmse <loss>=1.19511727467\u001b[0m\n",
      "\u001b[33m[08/20/2019 03:08:11 INFO 140385400035136] #quality_metric: host=algo-3, train mse <loss>=1.42830530022\u001b[0m\n",
      "\u001b[33m[08/20/2019 03:08:11 INFO 140385400035136] #quality_metric: host=algo-3, train absolute_loss <loss>=0.957702086217\u001b[0m\n",
      "\u001b[33m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2507.575035095215, \"sum\": 2507.575035095215, \"min\": 2507.575035095215}}, \"EndTime\": 1566270491.99947, \"Dimensions\": {\"Host\": \"algo-3\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1566270489.491439}\n",
      "\u001b[0m\n",
      "\u001b[33m[08/20/2019 03:08:11 INFO 140385400035136] #progress_metric: host=algo-3, completed 100 % of epochs\u001b[0m\n",
      "\u001b[33m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 206, \"sum\": 206.0, \"min\": 206}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 206, \"sum\": 206.0, \"min\": 206}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 205721, \"sum\": 205721.0, \"min\": 205721}, \"Total Batches Seen\": {\"count\": 1, \"max\": 619, \"sum\": 619.0, \"min\": 619}, \"Total Records Seen\": {\"count\": 1, \"max\": 618163, \"sum\": 618163.0, \"min\": 618163}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 205721, \"sum\": 205721.0, \"min\": 205721}, \"Reset Count\": {\"count\": 1, \"max\": 4, \"sum\": 4.0, \"min\": 4}}, \"EndTime\": 1566270491.999654, \"Dimensions\": {\"Host\": \"algo-3\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 2}, \"StartTime\": 1566270489.491866}\n",
      "\u001b[0m\n",
      "\u001b[33m[08/20/2019 03:08:11 INFO 140385400035136] #throughput_metric: host=algo-3, train throughput=82029.3515431 records/second\u001b[0m\n",
      "\u001b[31m[2019-08-20 03:08:12.777] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 4, \"duration\": 4184, \"num_examples\": 309, \"num_bytes\": 21961380}\u001b[0m\n",
      "\u001b[31m[08/20/2019 03:08:12 INFO 140399032596288] #quality_metric: host=algo-1, epoch=1, train rmse <loss>=1.20443179663\u001b[0m\n",
      "\u001b[31m[08/20/2019 03:08:12 INFO 140399032596288] #quality_metric: host=algo-1, epoch=1, train mse <loss>=1.45065595273\u001b[0m\n",
      "\u001b[31m[08/20/2019 03:08:12 INFO 140399032596288] #quality_metric: host=algo-1, epoch=1, train absolute_loss <loss>=0.964502358248\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4186.758041381836, \"sum\": 4186.758041381836, \"min\": 4186.758041381836}}, \"EndTime\": 1566270492.778178, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1566270488.591006}\n",
      "\u001b[0m\n",
      "\u001b[31m[08/20/2019 03:08:12 INFO 140399032596288] #progress_metric: host=algo-1, completed 66 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 309, \"sum\": 309.0, \"min\": 309}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 309, \"sum\": 309.0, \"min\": 309}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 308582, \"sum\": 308582.0, \"min\": 308582}, \"Total Batches Seen\": {\"count\": 1, \"max\": 619, \"sum\": 619.0, \"min\": 619}, \"Total Records Seen\": {\"count\": 1, \"max\": 618164, \"sum\": 618164.0, \"min\": 618164}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 308582, \"sum\": 308582.0, \"min\": 308582}, \"Reset Count\": {\"count\": 1, \"max\": 3, \"sum\": 3.0, \"min\": 3}}, \"EndTime\": 1566270492.778337, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 1}, \"StartTime\": 1566270488.591391}\n",
      "\u001b[0m\n",
      "\u001b[31m[08/20/2019 03:08:12 INFO 140399032596288] #throughput_metric: host=algo-1, train throughput=73699.0706139 records/second\u001b[0m\n",
      "\u001b[31m[08/20/2019 03:08:12 INFO 140399032596288] #quality_metric: host=algo-1, epoch=2, batch=0 train rmse <loss>=1.01574800938\u001b[0m\n",
      "\u001b[31m[08/20/2019 03:08:12 INFO 140399032596288] #quality_metric: host=algo-1, epoch=2, batch=0 train mse <loss>=1.03174401855\u001b[0m\n",
      "\u001b[31m[08/20/2019 03:08:12 INFO 140399032596288] #quality_metric: host=algo-1, epoch=2, batch=0 train absolute_loss <loss>=0.837033081055\u001b[0m\n",
      "\u001b[32m[08/20/2019 03:08:12 INFO 139979787347776] #quality_metric: host=algo-2, epoch=2, batch=0 train rmse <loss>=1.23004427202\u001b[0m\n",
      "\u001b[32m[08/20/2019 03:08:12 INFO 139979787347776] #quality_metric: host=algo-2, epoch=2, batch=0 train mse <loss>=1.51300891113\u001b[0m\n",
      "\u001b[32m[08/20/2019 03:08:12 INFO 139979787347776] #quality_metric: host=algo-2, epoch=2, batch=0 train absolute_loss <loss>=0.970998168945\u001b[0m\n",
      "\u001b[32m[2019-08-20 03:08:16.432] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 6, \"duration\": 3750, \"num_examples\": 309, \"num_bytes\": 21931124}\u001b[0m\n",
      "\u001b[32m[08/20/2019 03:08:16 INFO 139979787347776] #quality_metric: host=algo-2, epoch=2, train rmse <loss>=1.22575881134\u001b[0m\n",
      "\u001b[32m[08/20/2019 03:08:16 INFO 139979787347776] #quality_metric: host=algo-2, epoch=2, train mse <loss>=1.50248466358\u001b[0m\n",
      "\u001b[32m[08/20/2019 03:08:16 INFO 139979787347776] #quality_metric: host=algo-2, epoch=2, train absolute_loss <loss>=0.975214273101\u001b[0m\n",
      "\u001b[32m[08/20/2019 03:08:16 INFO 139979787347776] #quality_metric: host=algo-2, train rmse <loss>=1.22575881134\u001b[0m\n",
      "\u001b[32m[08/20/2019 03:08:16 INFO 139979787347776] #quality_metric: host=algo-2, train mse <loss>=1.50248466358\u001b[0m\n",
      "\u001b[32m[08/20/2019 03:08:16 INFO 139979787347776] #quality_metric: host=algo-2, train absolute_loss <loss>=0.975214273101\u001b[0m\n",
      "\u001b[32m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3752.9218196868896, \"sum\": 3752.9218196868896, \"min\": 3752.9218196868896}}, \"EndTime\": 1566270496.43283, \"Dimensions\": {\"Host\": \"algo-2\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1566270492.679221}\n",
      "\u001b[0m\n",
      "\u001b[32m[08/20/2019 03:08:16 INFO 139979787347776] #progress_metric: host=algo-2, completed 100 % of epochs\u001b[0m\n",
      "\u001b[32m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 309, \"sum\": 309.0, \"min\": 309}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 309, \"sum\": 309.0, \"min\": 309}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 308582, \"sum\": 308582.0, \"min\": 308582}, \"Total Batches Seen\": {\"count\": 1, \"max\": 928, \"sum\": 928.0, \"min\": 928}, \"Total Records Seen\": {\"count\": 1, \"max\": 926746, \"sum\": 926746.0, \"min\": 926746}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 308582, \"sum\": 308582.0, \"min\": 308582}, \"Reset Count\": {\"count\": 1, \"max\": 4, \"sum\": 4.0, \"min\": 4}}, \"EndTime\": 1566270496.432999, \"Dimensions\": {\"Host\": \"algo-2\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 2}, \"StartTime\": 1566270492.679885}\n",
      "\u001b[0m\n",
      "\u001b[32m[08/20/2019 03:08:16 INFO 139979787347776] #throughput_metric: host=algo-2, train throughput=82218.1113264 records/second\u001b[0m\n",
      "\u001b[32m[08/20/2019 03:08:17 INFO 139979787347776] Pulling entire model from kvstore to finalize\u001b[0m\n",
      "\u001b[32m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 22.73416519165039, \"sum\": 22.73416519165039, \"min\": 22.73416519165039}}, \"EndTime\": 1566270497.04551, \"Dimensions\": {\"Host\": \"algo-2\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1566270496.43289}\n",
      "\u001b[0m\n",
      "\u001b[32m[2019-08-20 03:08:17.046] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/test\", \"epoch\": 0, \"duration\": 14367, \"num_examples\": 1, \"num_bytes\": 70668}\u001b[0m\n",
      "\u001b[31m[2019-08-20 03:08:17.020] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 6, \"duration\": 4240, \"num_examples\": 309, \"num_bytes\": 21961380}\u001b[0m\n",
      "\u001b[31m[08/20/2019 03:08:17 INFO 140399032596288] #quality_metric: host=algo-1, epoch=2, train rmse <loss>=1.19965039573\u001b[0m\n",
      "\u001b[31m[08/20/2019 03:08:17 INFO 140399032596288] #quality_metric: host=algo-1, epoch=2, train mse <loss>=1.43916107197\u001b[0m\n",
      "\u001b[31m[08/20/2019 03:08:17 INFO 140399032596288] #quality_metric: host=algo-1, epoch=2, train absolute_loss <loss>=0.960882345749\u001b[0m\n",
      "\u001b[31m[08/20/2019 03:08:17 INFO 140399032596288] #quality_metric: host=algo-1, train rmse <loss>=1.19965039573\u001b[0m\n",
      "\u001b[31m[08/20/2019 03:08:17 INFO 140399032596288] #quality_metric: host=algo-1, train mse <loss>=1.43916107197\u001b[0m\n",
      "\u001b[31m[08/20/2019 03:08:17 INFO 140399032596288] #quality_metric: host=algo-1, train absolute_loss <loss>=0.960882345749\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4242.095947265625, \"sum\": 4242.095947265625, \"min\": 4242.095947265625}}, \"EndTime\": 1566270497.02107, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1566270492.778245}\n",
      "\u001b[0m\n",
      "\u001b[31m[08/20/2019 03:08:17 INFO 140399032596288] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 309, \"sum\": 309.0, \"min\": 309}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 309, \"sum\": 309.0, \"min\": 309}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 308582, \"sum\": 308582.0, \"min\": 308582}, \"Total Batches Seen\": {\"count\": 1, \"max\": 928, \"sum\": 928.0, \"min\": 928}, \"Total Records Seen\": {\"count\": 1, \"max\": 926746, \"sum\": 926746.0, \"min\": 926746}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 308582, \"sum\": 308582.0, \"min\": 308582}, \"Reset Count\": {\"count\": 1, \"max\": 4, \"sum\": 4.0, \"min\": 4}}, \"EndTime\": 1566270497.021205, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 2}, \"StartTime\": 1566270492.77895}\n",
      "\u001b[0m\n",
      "\u001b[31m[08/20/2019 03:08:17 INFO 140399032596288] #throughput_metric: host=algo-1, train throughput=72738.5100399 records/second\u001b[0m\n",
      "\u001b[31m[08/20/2019 03:08:17 INFO 140399032596288] Pulling entire model from kvstore to finalize\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 22.99189567565918, \"sum\": 22.99189567565918, \"min\": 22.99189567565918}}, \"EndTime\": 1566270497.0446, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1566270497.021127}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/20/2019 03:08:17 INFO 139675139647296] Pulling entire model from kvstore to finalize\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 26.1228084564209, \"sum\": 26.1228084564209, \"min\": 26.1228084564209}}, \"EndTime\": 1566270497.048812, \"Dimensions\": {\"Host\": \"algo-4\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1566270491.821341}\n",
      "\u001b[0m\n",
      "\u001b[34m[2019-08-20 03:08:17.050] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/test\", \"epoch\": 0, \"duration\": 14627, \"num_examples\": 1, \"num_bytes\": 70668}\u001b[0m\n",
      "\u001b[33m[08/20/2019 03:08:17 INFO 140385400035136] Pulling entire model from kvstore to finalize\u001b[0m\n",
      "\u001b[33m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 22.880077362060547, \"sum\": 22.880077362060547, \"min\": 22.880077362060547}}, \"EndTime\": 1566270497.042639, \"Dimensions\": {\"Host\": \"algo-3\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1566270491.999536}\n",
      "\u001b[0m\n",
      "\u001b[33m[2019-08-20 03:08:17.043] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/test\", \"epoch\": 0, \"duration\": 14664, \"num_examples\": 1, \"num_bytes\": 70668}\u001b[0m\n",
      "\u001b[31m[08/20/2019 03:08:17 INFO 140399032596288] Saved checkpoint to \"/tmp/tmp1zuDMl/state-0001.params\"\u001b[0m\n",
      "\u001b[31m[2019-08-20 03:08:18.308] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/test\", \"epoch\": 0, \"duration\": 16061, \"num_examples\": 1, \"num_bytes\": 70668}\u001b[0m\n",
      "\u001b[32m[2019-08-20 03:08:27.545] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/test\", \"epoch\": 1, \"duration\": 10496, \"num_examples\": 141, \"num_bytes\": 9937804}\u001b[0m\n",
      "\u001b[32m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 141, \"sum\": 141.0, \"min\": 141}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 141, \"sum\": 141.0, \"min\": 141}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 140344, \"sum\": 140344.0, \"min\": 140344}, \"Total Batches Seen\": {\"count\": 1, \"max\": 141, \"sum\": 141.0, \"min\": 141}, \"Total Records Seen\": {\"count\": 1, \"max\": 140344, \"sum\": 140344.0, \"min\": 140344}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 140344, \"sum\": 140344.0, \"min\": 140344}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1566270507.546099, \"Dimensions\": {\"Host\": \"algo-2\", \"Meta\": \"test_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1566270497.04582}\n",
      "\u001b[0m\n",
      "\u001b[32m[08/20/2019 03:08:27 INFO 139979787347776] #test_score (algo-2) : ('rmse', 50.258618808564755)\u001b[0m\n",
      "\u001b[32m[08/20/2019 03:08:27 INFO 139979787347776] #test_score (algo-2) : ('mse', 2525.928764544619)\u001b[0m\n",
      "\u001b[32m[08/20/2019 03:08:27 INFO 139979787347776] #test_score (algo-2) : ('absolute_loss', 31.294070228777148)\u001b[0m\n",
      "\u001b[32m[08/20/2019 03:08:27 INFO 139979787347776] #quality_metric: host=algo-2, test rmse <loss>=50.2586188086\u001b[0m\n",
      "\u001b[32m[08/20/2019 03:08:27 INFO 139979787347776] #quality_metric: host=algo-2, test mse <loss>=2525.92876454\u001b[0m\n",
      "\u001b[32m[08/20/2019 03:08:27 INFO 139979787347776] #quality_metric: host=algo-2, test absolute_loss <loss>=31.2940702288\u001b[0m\n",
      "\u001b[32m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 26427.685976028442, \"sum\": 26427.685976028442, \"min\": 26427.685976028442}, \"setuptime\": {\"count\": 1, \"max\": 1550.9250164031982, \"sum\": 1550.9250164031982, \"min\": 1550.9250164031982}}, \"EndTime\": 1566270507.547158, \"Dimensions\": {\"Host\": \"algo-2\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1566270497.045578}\n",
      "\u001b[0m\n",
      "\u001b[33m[2019-08-20 03:08:27.589] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/test\", \"epoch\": 1, \"duration\": 10543, \"num_examples\": 141, \"num_bytes\": 9937804}\u001b[0m\n",
      "\u001b[33m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 141, \"sum\": 141.0, \"min\": 141}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 141, \"sum\": 141.0, \"min\": 141}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 140344, \"sum\": 140344.0, \"min\": 140344}, \"Total Batches Seen\": {\"count\": 1, \"max\": 141, \"sum\": 141.0, \"min\": 141}, \"Total Records Seen\": {\"count\": 1, \"max\": 140344, \"sum\": 140344.0, \"min\": 140344}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 140344, \"sum\": 140344.0, \"min\": 140344}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1566270507.589894, \"Dimensions\": {\"Host\": \"algo-3\", \"Meta\": \"test_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1566270497.042922}\n",
      "\u001b[0m\n",
      "\u001b[33m[08/20/2019 03:08:27 INFO 140385400035136] #test_score (algo-3) : ('rmse', 50.258618808564755)\u001b[0m\n",
      "\u001b[33m[08/20/2019 03:08:27 INFO 140385400035136] #test_score (algo-3) : ('mse', 2525.928764544619)\u001b[0m\n",
      "\u001b[33m[08/20/2019 03:08:27 INFO 140385400035136] #test_score (algo-3) : ('absolute_loss', 31.294070228777148)\u001b[0m\n",
      "\u001b[33m[08/20/2019 03:08:27 INFO 140385400035136] #quality_metric: host=algo-3, test rmse <loss>=50.2586188086\u001b[0m\n",
      "\u001b[33m[08/20/2019 03:08:27 INFO 140385400035136] #quality_metric: host=algo-3, test mse <loss>=2525.92876454\u001b[0m\n",
      "\u001b[33m[08/20/2019 03:08:27 INFO 140385400035136] #quality_metric: host=algo-3, test absolute_loss <loss>=31.2940702288\u001b[0m\n",
      "\u001b[33m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 25278.874158859253, \"sum\": 25278.874158859253, \"min\": 25278.874158859253}, \"setuptime\": {\"count\": 1, \"max\": 44.01803016662598, \"sum\": 44.01803016662598, \"min\": 44.01803016662598}}, \"EndTime\": 1566270507.604613, \"Dimensions\": {\"Host\": \"algo-3\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1566270497.042708}\n",
      "\u001b[0m\n",
      "\u001b[34m[2019-08-20 03:08:27.685] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/test\", \"epoch\": 1, \"duration\": 10633, \"num_examples\": 141, \"num_bytes\": 9937804}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 141, \"sum\": 141.0, \"min\": 141}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 141, \"sum\": 141.0, \"min\": 141}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 140344, \"sum\": 140344.0, \"min\": 140344}, \"Total Batches Seen\": {\"count\": 1, \"max\": 141, \"sum\": 141.0, \"min\": 141}, \"Total Records Seen\": {\"count\": 1, \"max\": 140344, \"sum\": 140344.0, \"min\": 140344}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 140344, \"sum\": 140344.0, \"min\": 140344}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1566270507.686067, \"Dimensions\": {\"Host\": \"algo-4\", \"Meta\": \"test_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1566270497.049202}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/20/2019 03:08:27 INFO 139675139647296] #test_score (algo-4) : ('rmse', 50.258618808564755)\u001b[0m\n",
      "\u001b[34m[08/20/2019 03:08:27 INFO 139675139647296] #test_score (algo-4) : ('mse', 2525.928764544619)\u001b[0m\n",
      "\u001b[34m[08/20/2019 03:08:27 INFO 139675139647296] #test_score (algo-4) : ('absolute_loss', 31.294070228777148)\u001b[0m\n",
      "\u001b[34m[08/20/2019 03:08:27 INFO 139675139647296] #quality_metric: host=algo-4, test rmse <loss>=50.2586188086\u001b[0m\n",
      "\u001b[34m[08/20/2019 03:08:27 INFO 139675139647296] #quality_metric: host=algo-4, test mse <loss>=2525.92876454\u001b[0m\n",
      "\u001b[34m[08/20/2019 03:08:27 INFO 139675139647296] #quality_metric: host=algo-4, test absolute_loss <loss>=31.2940702288\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 26843.942165374756, \"sum\": 26843.942165374756, \"min\": 26843.942165374756}, \"setuptime\": {\"count\": 1, \"max\": 1555.1130771636963, \"sum\": 1555.1130771636963, \"min\": 1555.1130771636963}}, \"EndTime\": 1566270507.701748, \"Dimensions\": {\"Host\": \"algo-4\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1566270497.048903}\n",
      "\u001b[0m\n",
      "\u001b[31m[2019-08-20 03:08:28.572] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/test\", \"epoch\": 1, \"duration\": 10264, \"num_examples\": 141, \"num_bytes\": 9937804}\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 141, \"sum\": 141.0, \"min\": 141}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 141, \"sum\": 141.0, \"min\": 141}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 140344, \"sum\": 140344.0, \"min\": 140344}, \"Total Batches Seen\": {\"count\": 1, \"max\": 141, \"sum\": 141.0, \"min\": 141}, \"Total Records Seen\": {\"count\": 1, \"max\": 140344, \"sum\": 140344.0, \"min\": 140344}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 140344, \"sum\": 140344.0, \"min\": 140344}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1566270508.572846, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"test_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1566270498.307618}\n",
      "\u001b[0m\n",
      "\u001b[31m[08/20/2019 03:08:28 INFO 140399032596288] #test_score (algo-1) : ('rmse', 50.258618808564755)\u001b[0m\n",
      "\u001b[31m[08/20/2019 03:08:28 INFO 140399032596288] #test_score (algo-1) : ('mse', 2525.928764544619)\u001b[0m\n",
      "\u001b[31m[08/20/2019 03:08:28 INFO 140399032596288] #test_score (algo-1) : ('absolute_loss', 31.294070228777148)\u001b[0m\n",
      "\u001b[31m[08/20/2019 03:08:28 INFO 140399032596288] #quality_metric: host=algo-1, test rmse <loss>=50.2586188086\u001b[0m\n",
      "\u001b[31m[08/20/2019 03:08:28 INFO 140399032596288] #quality_metric: host=algo-1, test mse <loss>=2525.92876454\u001b[0m\n",
      "\u001b[31m[08/20/2019 03:08:28 INFO 140399032596288] #quality_metric: host=algo-1, test absolute_loss <loss>=31.2940702288\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 27428.59196662903, \"sum\": 27428.59196662903, \"min\": 27428.59196662903}, \"setuptime\": {\"count\": 1, \"max\": 1091.2110805511475, \"sum\": 1091.2110805511475, \"min\": 1091.2110805511475}}, \"EndTime\": 1566270508.574051, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1566270497.044668}\n",
      "\u001b[0m\n",
      "\n",
      "2019-08-20 03:08:31 Uploading - Uploading generated training model\n",
      "2019-08-20 03:08:55 Completed - Training job completed\n",
      "Billable seconds: 305\n"
     ]
    }
   ],
   "source": [
    "fm = sagemaker.estimator.Estimator(\n",
    "    sagemaker.amazon.amazon_estimator.get_image_uri(boto3.Session().region_name, 'factorization-machines', 'latest'),\n",
    "    role, \n",
    "    train_instance_count=4, \n",
    "    train_instance_type='ml.c5.2xlarge',\n",
    "    output_path='s3://{}/{}/output'.format(bucket, prefix),\n",
    "    base_job_name=base,\n",
    "    sagemaker_session=sess)\n",
    "\n",
    "fm.set_hyperparameters(\n",
    "    feature_dim=customer_index.shape[0] + product_index.shape[0] + 1,\n",
    "    predictor_type='regressor',\n",
    "    mini_batch_size=1000,\n",
    "    num_factors=256,\n",
    "    epochs=3)\n",
    "\n",
    "fm.fit({'train': sagemaker.s3_input('s3://{}/{}/train/'.format(bucket, prefix), distribution='ShardedByS3Key'), \n",
    "        'test': sagemaker.s3_input('s3://{}/{}/test/'.format(bucket, prefix), distribution='FullyReplicated')})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4 - Host the trained model\n",
    "\n",
    "Deploy trained model to a real-time production endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "fm_predictor = fm.deploy(instance_type='ml.m4.xlarge', initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup predictor to serialize in-memory data for invocation requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fm_serializer(df):\n",
    "    feature_dim = customer_index.shape[0] + product_index.shape[0] + 1\n",
    "    js = {'instances': []}\n",
    "    for index, data in df.iterrows():\n",
    "        js['instances'].append({'data': {'features': {'values': [1, 1, data['days_since_first']],\n",
    "                                                      'keys': [data['user'], data['item'], feature_dim - 1],\n",
    "                                                      'shape': [feature_dim]}}})\n",
    "    return json.dumps(js)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_predictor.content_type = 'application/json'\n",
    "fm_predictor.serializer = fm_serializer\n",
    "fm_predictor.deserializer = json_deserializer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Real-time prediction for what a single user would rate an item**\n",
    "\n",
    "1. Pick a customer-movie pair from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_title</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_date</th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>first_review_date</th>\n",
       "      <th>days_since_first</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10378</td>\n",
       "      <td>B002PZDM9Y</td>\n",
       "      <td>Ghosts of Girlfriends Past</td>\n",
       "      <td>4</td>\n",
       "      <td>2013-01-14</td>\n",
       "      <td>8644</td>\n",
       "      <td>173745</td>\n",
       "      <td>2012-12-28</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10981</td>\n",
       "      <td>B00NGFBS8E</td>\n",
       "      <td>Dead Snow 2: Red vs Dead</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-04</td>\n",
       "      <td>2400</td>\n",
       "      <td>152938</td>\n",
       "      <td>2014-03-05</td>\n",
       "      <td>486.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10998</td>\n",
       "      <td>B006GLLXXK</td>\n",
       "      <td>True Blood: Season 1</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-03-12</td>\n",
       "      <td>87285</td>\n",
       "      <td>140461</td>\n",
       "      <td>2015-03-12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11067</td>\n",
       "      <td>B00GQ7OZR0</td>\n",
       "      <td>Dexter Season 8</td>\n",
       "      <td>5</td>\n",
       "      <td>2014-07-17</td>\n",
       "      <td>65884</td>\n",
       "      <td>143933</td>\n",
       "      <td>2014-07-17</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11152</td>\n",
       "      <td>B003TKFQPC</td>\n",
       "      <td>Hung: Season 1</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-06-02</td>\n",
       "      <td>94841</td>\n",
       "      <td>154357</td>\n",
       "      <td>2015-05-05</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11685</td>\n",
       "      <td>B009GED3HS</td>\n",
       "      <td>How I Met Your Mother Season 8</td>\n",
       "      <td>5</td>\n",
       "      <td>2013-04-12</td>\n",
       "      <td>67370</td>\n",
       "      <td>142565</td>\n",
       "      <td>2013-04-12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12574</td>\n",
       "      <td>B0093SB8VU</td>\n",
       "      <td>Goon</td>\n",
       "      <td>4</td>\n",
       "      <td>2014-11-03</td>\n",
       "      <td>77169</td>\n",
       "      <td>146203</td>\n",
       "      <td>2014-11-03</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12783</td>\n",
       "      <td>B00IMZ16HQ</td>\n",
       "      <td>Knights of Badassdom</td>\n",
       "      <td>2</td>\n",
       "      <td>2014-11-02</td>\n",
       "      <td>4249</td>\n",
       "      <td>144127</td>\n",
       "      <td>2014-08-02</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13004</td>\n",
       "      <td>B00NXLX1VI</td>\n",
       "      <td>Days and Nights</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-02-14</td>\n",
       "      <td>86041</td>\n",
       "      <td>168219</td>\n",
       "      <td>2015-02-14</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13530</td>\n",
       "      <td>B003Y059EK</td>\n",
       "      <td>Return To Oz</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-02-28</td>\n",
       "      <td>93272</td>\n",
       "      <td>147508</td>\n",
       "      <td>2015-02-28</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>14344</td>\n",
       "      <td>B0040D6G3I</td>\n",
       "      <td>7 Signs of Christ's Return</td>\n",
       "      <td>5</td>\n",
       "      <td>2014-11-17</td>\n",
       "      <td>59265</td>\n",
       "      <td>153038</td>\n",
       "      <td>2014-09-14</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14489</td>\n",
       "      <td>B00T482BII</td>\n",
       "      <td>Ink &amp; Steel</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-08-09</td>\n",
       "      <td>49652</td>\n",
       "      <td>144767</td>\n",
       "      <td>2015-06-16</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14650</td>\n",
       "      <td>B00MUCX6AW</td>\n",
       "      <td>Live Die Repeat: Edge of Tomorrow</td>\n",
       "      <td>4</td>\n",
       "      <td>2014-10-21</td>\n",
       "      <td>125916</td>\n",
       "      <td>140501</td>\n",
       "      <td>2013-11-27</td>\n",
       "      <td>328.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15092</td>\n",
       "      <td>B009NXDEBM</td>\n",
       "      <td>Cinderfella</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-07-14</td>\n",
       "      <td>129083</td>\n",
       "      <td>166526</td>\n",
       "      <td>2013-07-14</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15719</td>\n",
       "      <td>B005WQ4QW0</td>\n",
       "      <td>Cape Fear (1991)</td>\n",
       "      <td>5</td>\n",
       "      <td>2014-10-28</td>\n",
       "      <td>54700</td>\n",
       "      <td>172422</td>\n",
       "      <td>2014-07-24</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16800</td>\n",
       "      <td>B00Z89NKNM</td>\n",
       "      <td>The Adventures of Knickerbock Teetertop Season 1</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>61105</td>\n",
       "      <td>146068</td>\n",
       "      <td>2014-09-22</td>\n",
       "      <td>281.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16804</td>\n",
       "      <td>B0019IIPXQ</td>\n",
       "      <td>Pitch Black</td>\n",
       "      <td>5</td>\n",
       "      <td>2014-03-23</td>\n",
       "      <td>111451</td>\n",
       "      <td>147546</td>\n",
       "      <td>2014-03-23</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16886</td>\n",
       "      <td>B001OSEYFE</td>\n",
       "      <td>The Man in the Iron Mask (1977)</td>\n",
       "      <td>5</td>\n",
       "      <td>2013-12-27</td>\n",
       "      <td>81366</td>\n",
       "      <td>165607</td>\n",
       "      <td>2013-06-02</td>\n",
       "      <td>208.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>17106</td>\n",
       "      <td>B0019KORCC</td>\n",
       "      <td>The Hollow</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-08-30</td>\n",
       "      <td>82343</td>\n",
       "      <td>172202</td>\n",
       "      <td>2015-04-30</td>\n",
       "      <td>122.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>17742</td>\n",
       "      <td>B00MFDMM3I</td>\n",
       "      <td>Need For Speed (Theatrical)</td>\n",
       "      <td>3</td>\n",
       "      <td>2014-09-22</td>\n",
       "      <td>128628</td>\n",
       "      <td>144858</td>\n",
       "      <td>2014-04-11</td>\n",
       "      <td>164.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>17976</td>\n",
       "      <td>B00447J4HA</td>\n",
       "      <td>My Dear Secretary - 1949</td>\n",
       "      <td>5</td>\n",
       "      <td>2013-05-06</td>\n",
       "      <td>41660</td>\n",
       "      <td>154704</td>\n",
       "      <td>2013-05-06</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>18438</td>\n",
       "      <td>B00942OO7U</td>\n",
       "      <td>Machine Gun Preacher</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-04-06</td>\n",
       "      <td>30454</td>\n",
       "      <td>142368</td>\n",
       "      <td>2014-07-07</td>\n",
       "      <td>273.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>18766</td>\n",
       "      <td>B0014C5HRY</td>\n",
       "      <td>The Postman Always Rings Twice (1981)</td>\n",
       "      <td>5</td>\n",
       "      <td>2014-04-11</td>\n",
       "      <td>65010</td>\n",
       "      <td>159134</td>\n",
       "      <td>2014-03-23</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>19112</td>\n",
       "      <td>B00CLIJ3PC</td>\n",
       "      <td>Escape From Planet Earth</td>\n",
       "      <td>3</td>\n",
       "      <td>2013-06-02</td>\n",
       "      <td>85817</td>\n",
       "      <td>154820</td>\n",
       "      <td>2013-06-02</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>19443</td>\n",
       "      <td>B0054NRPMO</td>\n",
       "      <td>True Grit (2010)</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-09</td>\n",
       "      <td>127237</td>\n",
       "      <td>143830</td>\n",
       "      <td>2015-07-09</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    customer_id  product_id                                     product_title  \\\n",
       "0         10378  B002PZDM9Y                        Ghosts of Girlfriends Past   \n",
       "1         10981  B00NGFBS8E                          Dead Snow 2: Red vs Dead   \n",
       "2         10998  B006GLLXXK                              True Blood: Season 1   \n",
       "3         11067  B00GQ7OZR0                                   Dexter Season 8   \n",
       "4         11152  B003TKFQPC                                    Hung: Season 1   \n",
       "5         11685  B009GED3HS                    How I Met Your Mother Season 8   \n",
       "6         12574  B0093SB8VU                                              Goon   \n",
       "7         12783  B00IMZ16HQ                              Knights of Badassdom   \n",
       "8         13004  B00NXLX1VI                                   Days and Nights   \n",
       "9         13530  B003Y059EK                                      Return To Oz   \n",
       "10        14344  B0040D6G3I                        7 Signs of Christ's Return   \n",
       "11        14489  B00T482BII                                       Ink & Steel   \n",
       "12        14650  B00MUCX6AW                 Live Die Repeat: Edge of Tomorrow   \n",
       "13        15092  B009NXDEBM                                       Cinderfella   \n",
       "14        15719  B005WQ4QW0                                  Cape Fear (1991)   \n",
       "15        16800  B00Z89NKNM  The Adventures of Knickerbock Teetertop Season 1   \n",
       "16        16804  B0019IIPXQ                                       Pitch Black   \n",
       "17        16886  B001OSEYFE                   The Man in the Iron Mask (1977)   \n",
       "18        17106  B0019KORCC                                        The Hollow   \n",
       "19        17742  B00MFDMM3I                       Need For Speed (Theatrical)   \n",
       "20        17976  B00447J4HA                          My Dear Secretary - 1949   \n",
       "21        18438  B00942OO7U                              Machine Gun Preacher   \n",
       "22        18766  B0014C5HRY             The Postman Always Rings Twice (1981)   \n",
       "23        19112  B00CLIJ3PC                          Escape From Planet Earth   \n",
       "24        19443  B0054NRPMO                                  True Grit (2010)   \n",
       "\n",
       "    star_rating review_date    user    item first_review_date  \\\n",
       "0             4  2013-01-14    8644  173745        2012-12-28   \n",
       "1             5  2015-07-04    2400  152938        2014-03-05   \n",
       "2             5  2015-03-12   87285  140461        2015-03-12   \n",
       "3             5  2014-07-17   65884  143933        2014-07-17   \n",
       "4             5  2015-06-02   94841  154357        2015-05-05   \n",
       "5             5  2013-04-12   67370  142565        2013-04-12   \n",
       "6             4  2014-11-03   77169  146203        2014-11-03   \n",
       "7             2  2014-11-02    4249  144127        2014-08-02   \n",
       "8             1  2015-02-14   86041  168219        2015-02-14   \n",
       "9             5  2015-02-28   93272  147508        2015-02-28   \n",
       "10            5  2014-11-17   59265  153038        2014-09-14   \n",
       "11            4  2015-08-09   49652  144767        2015-06-16   \n",
       "12            4  2014-10-21  125916  140501        2013-11-27   \n",
       "13            1  2013-07-14  129083  166526        2013-07-14   \n",
       "14            5  2014-10-28   54700  172422        2014-07-24   \n",
       "15            4  2015-06-30   61105  146068        2014-09-22   \n",
       "16            5  2014-03-23  111451  147546        2014-03-23   \n",
       "17            5  2013-12-27   81366  165607        2013-06-02   \n",
       "18            5  2015-08-30   82343  172202        2015-04-30   \n",
       "19            3  2014-09-22  128628  144858        2014-04-11   \n",
       "20            5  2013-05-06   41660  154704        2013-05-06   \n",
       "21            5  2015-04-06   30454  142368        2014-07-07   \n",
       "22            5  2014-04-11   65010  159134        2014-03-23   \n",
       "23            3  2013-06-02   85817  154820        2013-06-02   \n",
       "24            5  2015-07-09  127237  143830        2015-07-09   \n",
       "\n",
       "    days_since_first  \n",
       "0               17.0  \n",
       "1              486.0  \n",
       "2                0.0  \n",
       "3                0.0  \n",
       "4               28.0  \n",
       "5                0.0  \n",
       "6                0.0  \n",
       "7               92.0  \n",
       "8                0.0  \n",
       "9                0.0  \n",
       "10              64.0  \n",
       "11              54.0  \n",
       "12             328.0  \n",
       "13               0.0  \n",
       "14              96.0  \n",
       "15             281.0  \n",
       "16               0.0  \n",
       "17             208.0  \n",
       "18             122.0  \n",
       "19             164.0  \n",
       "20               0.0  \n",
       "21             273.0  \n",
       "22              19.0  \n",
       "23               0.0  \n",
       "24               0.0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Pull out a single customer-movie pair that we like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_title</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_date</th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>first_review_date</th>\n",
       "      <th>days_since_first</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>17976</td>\n",
       "      <td>B00447J4HA</td>\n",
       "      <td>My Dear Secretary - 1949</td>\n",
       "      <td>5</td>\n",
       "      <td>2013-05-06</td>\n",
       "      <td>41660</td>\n",
       "      <td>154704</td>\n",
       "      <td>2013-05-06</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    customer_id  product_id             product_title  star_rating  \\\n",
       "20        17976  B00447J4HA  My Dear Secretary - 1949            5   \n",
       "\n",
       "   review_date   user    item first_review_date  days_since_first  \n",
       "20  2013-05-06  41660  154704        2013-05-06               0.0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_customer = test_df.iloc[[20]]\n",
    "test_df.iloc[[20]] # peek at the data to confirm it's the one we wanted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Pass `test_customer` to predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': [{'score': 3.985922336578369}]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fm_predictor.predict(test_customer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now let's make a df for an arbitrary customer and movie pair and test it out!**\n",
    "\n",
    "Our `fm_serializer` requires 3 inputs to perform a prediction:\n",
    " - `user` id for a customer (type = num)\n",
    " - `item` id for a movie (type = num)\n",
    " - `days_since_first` review (type = double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_title</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_date</th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>first_review_date</th>\n",
       "      <th>days_since_first</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>17976</td>\n",
       "      <td>B00447J4HA</td>\n",
       "      <td>My Dear Secretary - 1949</td>\n",
       "      <td>5</td>\n",
       "      <td>2013-05-06</td>\n",
       "      <td>65884</td>\n",
       "      <td>140461</td>\n",
       "      <td>2013-05-06</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    customer_id  product_id             product_title  star_rating  \\\n",
       "20        17976  B00447J4HA  My Dear Secretary - 1949            5   \n",
       "\n",
       "   review_date   user    item first_review_date  days_since_first  \n",
       "20  2013-05-06  65884  140461        2013-05-06              10.0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_customer = test_customer # make a copy of the test_customer we pulled out before to modify\n",
    "desired_user_id = 65884 # person who rated Dexter with 5 stars\n",
    "desired_item_id = 140461 # Code for True Blood: Season 1\n",
    "desired_review_days = 10.0 # arbitrary number of days since first review\n",
    "\n",
    "#fake_customer_data = {'user' : desired_user_id, 'item' : desired_item_id, 'days_since_first' : desired_review_days}\n",
    "#fake_customer = pd.DataFrame(fake_customer_data, index=[0])\n",
    "fake_customer['user'] = desired_user_id\n",
    "fake_customer['item'] = desired_item_id\n",
    "fake_customer['days_since_first'] = desired_review_days\n",
    "\n",
    "# print the details for this fake customer\n",
    "fake_customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': [{'score': 2.6590118408203125}]}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fm_predictor.predict(fake_customer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final step: Clean-up the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finished?\n",
    "\n",
    "Got some extra time? Feel free to go on to the Extra Credit below! \n",
    "\n",
    "**Note**: Amazon SageMaker automatically handles provisioning and tearing down of resources during training. Once deployed, the model's endpoint will persist independent of this notebook, and can be removed with the cell directly above this. \n",
    "\n",
    "If you are done working with this notebook demo, it is strongly advised that you stop the SageMaker hosted notebook instance if you do not wish to continue using it (and incurring costs). This can easily be done by clicking on \"Notebook instances\" from the SageMaker console."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Extra credit \n",
    "## (not covered in today's lab)\n",
    "\n",
    "- What happens when a new movie is added?\n",
    "  - No feature to set to \"1\" in the dataset\n",
    "  - No previous ratings to find similar items\n",
    "  - Cold start problem is hard with factorization machines\n",
    "- Word2vec\n",
    "  - Word embeddings for natural language processing (similar words get similar vectors)\n",
    "  - Use concatenated product titles as words, customer review history as sentences\n",
    "  - SageMaker BlazingText is an extremely fast implementation that can work with subwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Data\n",
    "\n",
    "Concatenate product titles to treat each one as a single word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_df['product_title'] = reduced_df['product_title'].apply(lambda x: x.lower().replace(' ', '-'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write customer purchase histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = True\n",
    "with open('customer_purchases.txt', 'w') as f:\n",
    "    for customer, data in reduced_df.sort_values(['customer_id', 'review_date']).groupby('customer_id'):\n",
    "        if first:\n",
    "            first = False\n",
    "        else:\n",
    "            f.write('\\n')\n",
    "        f.write(' '.join(data['product_title'].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write to S3 so SageMaker training can use it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = sess.upload_data('customer_purchases.txt', bucket, '{}/word2vec/train'.format(prefix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Train\n",
    "\n",
    "Create a SageMaker estimator:\n",
    "- Specify training job arguments\n",
    "- Set hyperparameters\n",
    "  - Remove titles that occur less than 5 times\n",
    "  - Embed in a 100-dimensional subspace\n",
    "  - Use subwords to capture similarity in titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt = sagemaker.estimator.Estimator(\n",
    "    sagemaker.amazon.amazon_estimator.get_image_uri(boto3.Session().region_name, 'blazingtext', 'latest'),\n",
    "    role, \n",
    "    train_instance_count=1, \n",
    "    train_instance_type='ml.p3.2xlarge',\n",
    "    train_volume_size = 5,\n",
    "    output_path='s3://{}/{}/output'.format(bucket, prefix),\n",
    "    sagemaker_session=sess)\n",
    "\n",
    "bt.set_hyperparameters(mode=\"skipgram\",\n",
    "    epochs=10,\n",
    "    min_count=5,\n",
    "    sampling_threshold=0.0001,\n",
    "    learning_rate=0.05,\n",
    "    window_size=5,\n",
    "    vector_dim=100,\n",
    "    negative_samples=5,\n",
    "    min_char=5,\n",
    "    max_char=10,\n",
    "    evaluation=False,\n",
    "    subwords=True)\n",
    "\n",
    "bt.fit({'train': sagemaker.s3_input(inputs, distribution='FullyReplicated', content_type='text/plain')})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Model\n",
    "\n",
    "- Bring in and extract the model from S3\n",
    "- Take a look at the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp $bt.model_data ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xvzf model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = pd.read_csv('vectors.txt', delimiter=' ', skiprows=2, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the embeddings appear to have meaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors.sort_values(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors.sort_values(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, but there's 100.  Let's reduce this further with t-SNE and map the top 100 titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_titles = vectors[0]\n",
    "vectors = vectors.drop([0, 101], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(perplexity=40, n_components=2, init='pca', n_iter=10000)\n",
    "embeddings = tsne.fit_transform(vectors.values[:100, ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pylab\n",
    "%matplotlib inline\n",
    "\n",
    "def plot(embeddings, labels):\n",
    "    pylab.figure(figsize=(20,20))\n",
    "    for i, label in enumerate(labels):\n",
    "        x, y = embeddings[i,:]\n",
    "        pylab.scatter(x, y)\n",
    "        pylab.annotate(label, xy=(x, y), xytext=(5, 2), textcoords='offset points',\n",
    "                       ha='right', va='bottom')\n",
    "    pylab.show()\n",
    "\n",
    "plot(embeddings, product_titles[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Host\n",
    "\n",
    "Deploy our model to a real-time endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt_endpoint = bt.deploy(initial_instance_count = 1,instance_type = 'ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try generating predictions for a set of titles (some of which are real, some of which are made up)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\"sherlock-season-1\", \n",
    "         \"sherlock-season-2\",\n",
    "         \"sherlock-season-5\",\n",
    "         'arbitrary-sherlock-holmes-string',\n",
    "         'the-imitation-game',\n",
    "         \"abcdefghijklmn\",\n",
    "         \"keeping-up-with-the-kardashians-season-1\"]\n",
    "\n",
    "payload = {\"instances\" : words}\n",
    "\n",
    "response = bt_endpoint.predict(json.dumps(payload))\n",
    "\n",
    "vecs_df = pd.DataFrame(json.loads(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate correlation and distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs_df = pd.DataFrame(vecs_df['vector'].values.tolist(), index=vecs_df['word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs_df = vecs_df.transpose()\n",
    "vecs_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in vecs_df.columns:\n",
    "    print(column + ':', np.sum((vecs_df[column] - vecs_df['sherlock-season-1']) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relative to 'sherlock-season-1':\n",
    "- 'sherlock-season-5' is made up, but relates well with 'sherlock-season-1' and 'sherlock-season-2'\n",
    "- 'arbitrary-sherlock-holmes-string' is also made up and relates less well but still fairly strong\n",
    "- 'the-imitation-game' is another popular Prime video title starring Benedict Cumberbatch and has a moderate relationship, but worse than the arbitrary Sherlock title\n",
    "- 'abcdefghijklmn' is made up and relates even worse\n",
    "- 'keeping-up-with-the-kardashians-season-1' somehow manages to relate even worse\n",
    "\n",
    "Clean-up the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt_endpoint.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "---\n",
    "\n",
    "# Wrap-up\n",
    "\n",
    "- Built a recommender system on a large dataset quickly and accurately\n",
    "- Add more features to extend\n",
    "- Compare to other methods\n",
    "- Ensemble two models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
